{"timestamp": "2025-06-16 11:21:00,389", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:21:00,396", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:21:00,397", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:21:00,400", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:21:00,402", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:21:00,416", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:21:00,417", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:21:00,422", "level": "INFO", "logger": "root", "message": "Created new FAISS index with dimension 384", "module": "faiss_store", "function": "_create_new_index", "line": 141}
{"timestamp": "2025-06-16 11:21:00,423", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 384", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:21:00,425", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-06-16 11:21:01,398", "level": "INFO", "logger": "root", "message": "Loaded SentenceTransformer model: sentence-transformers/all-MiniLM-L6-v2", "module": "embedder", "function": "_load_model", "line": 47}
{"timestamp": "2025-06-16 11:21:01,415", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: sentence-transformers", "module": "embedder", "function": "__init__", "line": 153}
{"timestamp": "2025-06-16 11:21:01,416", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-06-16 11:21:01,417", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['ingestion_engine', 'json_store', 'metadata_store', 'servicenow_integration', 'log_store', 'faiss_store', 'query_engine', 'reranker', 'llm_client', 'embedder', 'query_enhancer', 'config_manager', 'chunker']}", "module": "system_init", "function": "log_system_info", "line": 313}
{"timestamp": "2025-06-16 11:21:01,599", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-06-16 11:21:01,599", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 59}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking: size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 38}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 84}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Excel processor registered without Azure AI support", "module": "ingestion_engine", "function": "_register_excel_processor", "line": 55}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized", "module": "ingestion_engine", "function": "__init__", "line": 29}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Looking for existing vectors for file_path: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx, doc_path: facility_managers_2024.xlsx, filename: None", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 166}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "No existing vectors found for file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 217}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "ExcelProcessor", "message": "Processing Excel file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx", "module": "excel_processor", "function": "process", "line": 99}
{"timestamp": "2025-06-16 11:21:01,844", "level": "INFO", "logger": "ExcelProcessor", "message": "Successfully processed Excel file with 3 sheets, 0 embedded objects, 0 images", "module": "excel_processor", "function": "process", "line": 160}
{"timestamp": "2025-06-16 11:21:02,334", "level": "INFO", "logger": "root", "message": "Saved FAISS index and metadata", "module": "faiss_store", "function": "save_index", "line": 493}
{"timestamp": "2025-06-16 11:21:02,335", "level": "INFO", "logger": "root", "message": "Added 1 vectors to FAISS index", "module": "faiss_store", "function": "add_vectors", "line": 226}
{"timestamp": "2025-06-16 11:21:02,335", "level": "INFO", "logger": "root", "message": "Successfully ingested file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx (1 chunks)", "module": "ingestion_engine", "function": "ingest_file", "line": 135}
{"timestamp": "2025-06-16 11:23:17,038", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:23:17,046", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:23:17,047", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:23:17,047", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:23:17,050", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:23:17,052", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:23:17,052", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:23:17,095", "level": "INFO", "logger": "root", "message": "Loaded existing FAISS index with 1 vectors", "module": "faiss_store", "function": "_initialize_index", "line": 51}
{"timestamp": "2025-06-16 11:23:17,097", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 384", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:23:17,099", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-06-16 11:23:18,342", "level": "INFO", "logger": "root", "message": "Loaded SentenceTransformer model: sentence-transformers/all-MiniLM-L6-v2", "module": "embedder", "function": "_load_model", "line": 47}
{"timestamp": "2025-06-16 11:23:18,342", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: sentence-transformers", "module": "embedder", "function": "__init__", "line": 153}
{"timestamp": "2025-06-16 11:23:18,342", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-06-16 11:23:18,355", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['chunker', 'llm_client', 'config_manager', 'faiss_store', 'query_engine', 'ingestion_engine', 'servicenow_integration', 'json_store', 'embedder', 'metadata_store', 'query_enhancer', 'reranker', 'log_store']}", "module": "system_init", "function": "log_system_info", "line": 313}
{"timestamp": "2025-06-16 11:23:18,534", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-06-16 11:23:18,534", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-06-16 11:23:18,762", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 59}
{"timestamp": "2025-06-16 11:23:18,762", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking: size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 38}
{"timestamp": "2025-06-16 11:23:18,762", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 84}
{"timestamp": "2025-06-16 11:23:18,763", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Excel processor registered without Azure AI support", "module": "ingestion_engine", "function": "_register_excel_processor", "line": 55}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized", "module": "ingestion_engine", "function": "__init__", "line": 29}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Looking for existing vectors for file_path: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx, doc_path: facility_managers_2024.xlsx, filename: None", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 166}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Found matching vector 0: doc_path match: facility_managers_2024.xlsx", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 208}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Found 1 existing vectors", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 211}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Saved FAISS index and metadata", "module": "faiss_store", "function": "save_index", "line": 493}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Cleaned up 1 deleted vectors", "module": "faiss_store", "function": "_cleanup_deleted_vectors", "line": 106}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Deleted 1 vectors", "module": "faiss_store", "function": "delete_vectors", "line": 414}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Deleted 1 old vectors for file update", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 214}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "ExcelProcessor", "message": "Processing Excel file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx", "module": "excel_processor", "function": "process", "line": 99}
{"timestamp": "2025-06-16 11:23:18,780", "level": "INFO", "logger": "ExcelProcessor", "message": "Successfully processed Excel file with 3 sheets, 0 embedded objects, 0 images", "module": "excel_processor", "function": "process", "line": 160}
{"timestamp": "2025-06-16 11:23:18,872", "level": "INFO", "logger": "root", "message": "Saved FAISS index and metadata", "module": "faiss_store", "function": "save_index", "line": 493}
{"timestamp": "2025-06-16 11:23:18,873", "level": "INFO", "logger": "root", "message": "Added 1 vectors to FAISS index", "module": "faiss_store", "function": "add_vectors", "line": 226}
{"timestamp": "2025-06-16 11:23:18,874", "level": "INFO", "logger": "root", "message": "Successfully ingested file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx (1 chunks)", "module": "ingestion_engine", "function": "ingest_file", "line": 135}
{"timestamp": "2025-06-16 11:23:18,874", "level": "INFO", "logger": "root", "message": "Replaced 1 old vectors for updated file", "module": "ingestion_engine", "function": "ingest_file", "line": 137}
{"timestamp": "2025-06-16 11:26:34,619", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:26:34,621", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:26:34,621", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:26:34,621", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:26:34,623", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:26:34,625", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:26:34,625", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:26:34,636", "level": "INFO", "logger": "root", "message": "Loaded existing FAISS index with 1 vectors", "module": "faiss_store", "function": "_initialize_index", "line": 51}
{"timestamp": "2025-06-16 11:26:34,636", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 384", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:26:34,639", "level": "ERROR", "logger": "root", "message": "\u274c RAG System initialization failed: Unsupported embedding provider: azure", "module": "system_init", "function": "initialize_system", "line": 293}
{"timestamp": "2025-06-16 11:30:26,644", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:30:26,644", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:30:26,644", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:30:26,651", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:30:26,652", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:30:26,654", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:30:26,654", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:30:26,676", "level": "INFO", "logger": "root", "message": "Loaded existing FAISS index with 1 vectors", "module": "faiss_store", "function": "_initialize_index", "line": 51}
{"timestamp": "2025-06-16 11:30:26,677", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 1024", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:30:27,253", "level": "INFO", "logger": "root", "message": "Loaded Cohere client with model: embed-english-v3.0", "module": "embedder", "function": "_load_client", "line": 96}
{"timestamp": "2025-06-16 11:30:27,349", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 401 Unauthorized\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-06-16 11:30:27,396", "level": "ERROR", "logger": "root", "message": "\u274c RAG System initialization failed: Failed to initialize Cohere client: status_code: 401, body: {'message': 'invalid api token'}", "module": "system_init", "function": "initialize_system", "line": 293}
{"timestamp": "2025-06-16 11:40:16,142", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:40:16,145", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:40:16,145", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:40:16,146", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:40:16,147", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:40:16,149", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:40:16,149", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:40:16,164", "level": "INFO", "logger": "root", "message": "Loaded existing FAISS index with 1 vectors", "module": "faiss_store", "function": "_initialize_index", "line": 51}
{"timestamp": "2025-06-16 11:40:16,165", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 1024", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:40:16,730", "level": "INFO", "logger": "root", "message": "Loaded Cohere client with model: embed-english-v3.0", "module": "embedder", "function": "_load_client", "line": 96}
{"timestamp": "2025-06-16 11:40:16,951", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 401 Unauthorized\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-06-16 11:40:16,954", "level": "ERROR", "logger": "root", "message": "\u274c RAG System initialization failed: Failed to initialize Cohere client: status_code: 401, body: {'message': 'invalid api token'}", "module": "system_init", "function": "initialize_system", "line": 293}
{"timestamp": "2025-07-01 07:15:01,783", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 07:15:01,808", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 07:15:01,810", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 07:15:01,812", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 07:15:01,823", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 07:15:01,825", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 07:15:03,156", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:03,170", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:03,173", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 07:15:03,174", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 07:15:03,535", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 07:15:03,537", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '1bad8219-564b-11f0-a409-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 07:15:03,612", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 07:15:02 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 07:15:03,616", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 07:15:03,616", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 07:15:03,947", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 07:15:03,950", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 07:15:03,951", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 07:15:03,952", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['ingestion_engine', 'ingestion_debugger', 'ingestion_verifier', 'llm_client', 'vector_store', 'chunker', 'reranker', 'embedder', 'config_manager', 'log_store', 'json_store', 'query_enhancer', 'query_engine', 'metadata_store', 'servicenow_integration', 'faiss_store', 'conversation_manager', 'verified_ingestion_engine']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 07:15:04,574", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model memory manager initialized - Max memory: 2048MB, Idle timeout: 300s", "module": "model_memory_manager", "function": "__init__", "line": 95}
{"timestamp": "2025-07-01 07:15:04,575", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Loading model: semantic_chunker_all-MiniLM-L6-v2", "module": "model_memory_manager", "function": "get_model", "line": 117}
{"timestamp": "2025-07-01 07:15:04,575", "level": "INFO", "logger": "root", "message": "Loading sentence transformer: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "load_model", "line": 340}
{"timestamp": "2025-07-01 07:15:04,577", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-07-01 07:15:04,577", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-07-01 07:15:06,444", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 loaded in 1.87s. Current memory: 515.52MB", "module": "model_memory_manager", "function": "get_model", "line": 144}
{"timestamp": "2025-07-01 07:15:06,445", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with memory-managed model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 345}
{"timestamp": "2025-07-01 07:15:06,445", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking (model loads on demand): size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 47}
{"timestamp": "2025-07-01 07:15:06,448", "level": "INFO", "logger": "root", "message": "Progress tracker initialized", "module": "progress_tracker", "function": "__init__", "line": 172}
{"timestamp": "2025-07-01 07:15:06,448", "level": "INFO", "logger": "root", "message": "DEBUG: Created processor config with keys: ['chunk_size', 'chunk_overlap', 'supported_formats', 'max_file_size_mb', 'batch_size', 'timeout', 'file_timeout']", "module": "ingestion_engine", "function": "__init__", "line": 45}
{"timestamp": "2025-07-01 07:15:06,448", "level": "INFO", "logger": "root", "message": "Azure AI config added to processor config", "module": "ingestion_engine", "function": "__init__", "line": 54}
{"timestamp": "2025-07-01 07:15:06,450", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 85}
{"timestamp": "2025-07-01 07:15:06,450", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,450", "level": "INFO", "logger": "root", "message": "Extracted Azure AI config from general config", "module": "pdf_processor", "function": "create_pdf_processor", "line": 82}
{"timestamp": "2025-07-01 07:15:06,513", "level": "INFO", "logger": "rag_system.src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 07:15:06,513", "level": "INFO", "logger": "root", "message": "Azure AI client created successfully for PDF processing", "module": "pdf_processor", "function": "create_pdf_processor", "line": 93}
{"timestamp": "2025-07-01 07:15:06,513", "level": "INFO", "logger": "root", "message": "Azure CV endpoint: https://computervision1298.cognitiveservices.azure...", "module": "pdf_processor", "function": "create_pdf_processor", "line": 94}
{"timestamp": "2025-07-01 07:15:06,514", "level": "INFO", "logger": "root", "message": "Using EnhancedPDFProcessor with Azure AI integration", "module": "pdf_processor", "function": "create_pdf_processor", "line": 106}
{"timestamp": "2025-07-01 07:15:06,514", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,514", "level": "INFO", "logger": "WordProcessor", "message": "Word processor initialized", "module": "word_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 07:15:06,514", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: WordProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "ImageProcessor", "message": "Image processor initialized", "module": "image_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ImageProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "ServiceNowProcessor", "message": "ServiceNow processor initialized", "module": "servicenow_processor", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ServiceNowProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "TextProcessor", "message": "Text processor initialized", "module": "text_processor", "function": "__init__", "line": 30}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: TextProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,518", "level": "INFO", "logger": "rag_system.src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 07:15:06,519", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,519", "level": "INFO", "logger": "root", "message": "Enhanced PDF Processor with Azure CV registered successfully", "module": "ingestion_engine", "function": "__init__", "line": 73}
{"timestamp": "2025-07-01 07:15:06,521", "level": "INFO", "logger": "root", "message": "Processor registry initialized with 7 processors", "module": "ingestion_engine", "function": "__init__", "line": 77}
{"timestamp": "2025-07-01 07:15:06,521", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized with managed metadata", "module": "ingestion_engine", "function": "__init__", "line": 89}
{"timestamp": "2025-07-01 07:15:06,584", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:06,586", "level": "INFO", "logger": "root", "message": "\ud83d\udd0d Using processor: TextProcessor for C:\\Users\\JAIDEE~2\\AppData\\Local\\Temp\\tmpvr5jvggn.txt", "module": "ingestion_engine", "function": "_extract_text", "line": 734}
{"timestamp": "2025-07-01 07:15:06,588", "level": "INFO", "logger": "root", "message": "\ud83d\udd0d Using processor: TextProcessor for C:\\Users\\JAIDEE~2\\AppData\\Local\\Temp\\tmpvr5jvggn.txt", "module": "ingestion_engine", "function": "_extract_text", "line": 746}
{"timestamp": "2025-07-01 07:15:06,589", "level": "INFO", "logger": "TextProcessor", "message": "Processing text file: C:\\Users\\JAIDEE~2\\AppData\\Local\\Temp\\tmpvr5jvggn.txt", "module": "text_processor", "function": "process", "line": 66}
{"timestamp": "2025-07-01 07:15:06,591", "level": "INFO", "logger": "root", "message": "\u2705 Processor succeeded, chunks: 1", "module": "ingestion_engine", "function": "_extract_text", "line": 754}
{"timestamp": "2025-07-01 07:15:06,591", "level": "INFO", "logger": "root", "message": "   Processing time: 0.00s", "module": "ingestion_engine", "function": "_extract_text", "line": 755}
{"timestamp": "2025-07-01 07:15:06,593", "level": "INFO", "logger": "root", "message": "Using 1 chunks from processor", "module": "ingestion_engine", "function": "ingest_file", "line": 326}
{"timestamp": "2025-07-01 07:15:06,610", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '584'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '1d8251f9-564b-11f0-9a5a-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 07:15:06,663", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 07:15:05 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 07:15:06,672", "level": "WARNING", "logger": "root", "message": "Flattening nested metadata structure - this should be avoided in future", "module": "metadata_manager", "function": "normalize", "line": 205}
{"timestamp": "2025-07-01 07:15:06,676", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'file_size' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,678", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'content_type' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,678", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'original_filename' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,679", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'filename' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,679", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'upload_source' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,679", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'upload_timestamp' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,680", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'description' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,680", "level": "INFO", "logger": "root", "message": "Removing conflicting key 'file_name', keeping 'filename'", "module": "metadata_manager", "function": "normalize", "line": 227}
{"timestamp": "2025-07-01 07:15:06,680", "level": "INFO", "logger": "root", "message": "Removing conflicting key 'content', keeping 'text'", "module": "metadata_manager", "function": "normalize", "line": 227}
{"timestamp": "2025-07-01 07:15:06,930", "level": "INFO", "logger": "httpx", "message": "HTTP Request: PUT http://localhost:6333/collections/rag_documents/points?wait=true \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:06,932", "level": "INFO", "logger": "root", "message": "Added 1 vectors to Qdrant", "module": "qdrant_store", "function": "add_vectors", "line": 123}
{"timestamp": "2025-07-01 07:15:06,933", "level": "INFO", "logger": "root", "message": "Successfully ingested file: C:\\Users\\JAIDEE~2\\AppData\\Local\\Temp\\tmpvr5jvggn.txt (1 chunks)", "module": "ingestion_engine", "function": "ingest_file", "line": 519}
{"timestamp": "2025-07-01 07:15:06,940", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:06,963", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Shutting down model memory manager...", "module": "model_memory_manager", "function": "shutdown", "line": 413}
{"timestamp": "2025-07-01 07:15:07,264", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 unloaded. Current memory: 516.59MB", "module": "model_memory_manager", "function": "_unload_model", "line": 260}
{"timestamp": "2025-07-01 07:15:07,566", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model memory manager shutdown complete", "module": "model_memory_manager", "function": "shutdown", "line": 426}
{"timestamp": "2025-07-01 07:15:58,646", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 07:15:58,655", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 07:15:58,656", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 07:15:58,657", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 07:15:58,668", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 07:15:58,669", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 07:15:59,902", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:59,908", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:59,910", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 07:15:59,910", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 07:16:00,244", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 07:16:00,245", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '3d7a556d-564b-11f0-93ac-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 07:16:00,391", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 07:16:00 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 07:16:00,397", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 07:16:00,397", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 07:16:00,678", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 07:16:00,680", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 07:16:00,682", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 07:16:00,683", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['ingestion_verifier', 'embedder', 'chunker', 'servicenow_integration', 'config_manager', 'json_store', 'reranker', 'conversation_manager', 'verified_ingestion_engine', 'ingestion_debugger', 'ingestion_engine', 'log_store', 'metadata_store', 'faiss_store', 'llm_client', 'vector_store', 'query_engine', 'query_enhancer']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 07:16:00,693", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:49,729", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 07:36:49,734", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 07:36:49,734", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 07:36:49,736", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 07:36:49,738", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 07:36:49,738", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 07:36:51,361", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:51,368", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:51,370", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 07:36:51,372", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 07:36:51,778", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 07:36:51,780", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '27733afd-564e-11f0-b3b7-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 07:36:51,942", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 07:36:51 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 07:36:51,949", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 07:36:51,949", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 07:36:52,311", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 07:36:52,313", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 07:36:52,324", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 07:36:52,325", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['chunker', 'faiss_store', 'vector_store', 'verified_ingestion_engine', 'ingestion_verifier', 'log_store', 'embedder', 'query_engine', 'llm_client', 'config_manager', 'ingestion_debugger', 'servicenow_integration', 'json_store', 'reranker', 'query_enhancer', 'metadata_store', 'conversation_manager', 'ingestion_engine']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 07:36:52,819", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Initialized Memory checkpointer for state persistence", "module": "conversation_graph", "function": "__init__", "line": 36}
{"timestamp": "2025-07-01 07:36:52,838", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Conversation graph compiled successfully with Memory state persistence", "module": "conversation_graph", "function": "_build_graph", "line": 104}
{"timestamp": "2025-07-01 07:36:52,838", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "ConversationGraph initialized with state persistence", "module": "conversation_graph", "function": "__init__", "line": 41}
{"timestamp": "2025-07-01 07:36:52,839", "level": "WARNING", "logger": "rag_system.src.conversation.conversation_graph", "message": "Checkpointer not available or missing client attribute", "module": "conversation_graph", "function": "list_conversation_threads", "line": 309}
{"timestamp": "2025-07-01 07:36:52,840", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "Conversation cleanup completed: 0 old conversations removed", "module": "conversation_manager", "function": "cleanup_old_conversations", "line": 173}
{"timestamp": "2025-07-01 07:36:52,840", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "Initial conversation cleanup: 0 conversations removed", "module": "conversation_manager", "function": "__init__", "line": 34}
{"timestamp": "2025-07-01 07:36:52,840", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "ConversationManager initialized with LangGraph state persistence and memory management", "module": "conversation_manager", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 07:36:52,842", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Created new conversation state for thread 6de94747-1d16-412b-a0e2-38da559ebc2c", "module": "conversation_graph", "function": "_get_or_create_state", "line": 259}
{"timestamp": "2025-07-01 07:36:52,871", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 07:36:52,872", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 07:36:52,873", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Routing after understanding - intent: None, turn: 1", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 07:36:52,874", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 07:36:52,874", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 07:36:52,886", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 07:36:52,888", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Response generated without search results", "module": "conversation_nodes", "function": "generate_response", "line": 354}
{"timestamp": "2025-07-01 07:36:52,889", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 07:36:52,889", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=None, turns=2", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 07:36:52,891", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 6de94747-1d16-412b-a0e2-38da559ebc2c, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 07:36:52,891", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "Started/retrieved conversation for thread: 6de94747-1d16-412b-a0e2-38da559ebc2c", "module": "conversation_manager", "function": "start_conversation", "line": 53}
{"timestamp": "2025-07-01 07:36:52,892", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 6de94747-1d16-412b-a0e2-38da559ebc2c", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 07:36:52,895", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 07:36:52,895", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 07:36:52,898", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Conversation has history - treating with partial context", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 424}
{"timestamp": "2025-07-01 07:36:52,898", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Building contextual query from: 'How many routers are in the system?'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 07:36:52,899", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Enhanced query to: 'How many routers are in the system? (context: )'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 07:36:52,899", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'How many routers are in the system? (context: )'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 07:36:52,900", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['many', 'routers', 'system']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 07:36:52,901", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 07:36:52,901", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 07:36:52,902", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 3", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 07:36:52,903", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 07:36:52,904", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 07:36:52,904", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'How many routers are in the system? (context: )'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 07:36:52,905", "level": "INFO", "logger": "root", "message": "Query type detected: aggregation", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 07:36:52,959", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:52,966", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:52,984", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,012", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,018", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,020", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Search strategy 2: Original query: 'How many routers are in the system?'", "module": "conversation_nodes", "function": "search_knowledge", "line": 182}
{"timestamp": "2025-07-01 07:36:53,020", "level": "INFO", "logger": "root", "message": "Query type detected: aggregation", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 07:36:53,025", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,030", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,046", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,053", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,061", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,064", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 07:36:53,072", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'aggregation_results', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 07:36:53,072", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "No sources found in search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 262}
{"timestamp": "2025-07-01 07:36:53,073", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 07:36:53,074", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 07:36:53,074", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Using query engine response directly", "module": "conversation_nodes", "function": "_generate_contextual_response", "line": 513}
{"timestamp": "2025-07-01 07:36:53,076", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83d\ude80 Generating follow-up questions", "module": "conversation_nodes", "function": "generate_response", "line": 337}
{"timestamp": "2025-07-01 07:36:53,076", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83d\udd25 FOLLOW-UP QUESTIONS METHOD CALLED \ud83d\udd25", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 722}
{"timestamp": "2025-07-01 07:36:53,076", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Starting follow-up question generation", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 738}
{"timestamp": "2025-07-01 07:36:53,077", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Built context info with length: 331", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 747}
{"timestamp": "2025-07-01 07:36:53,077", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Sending prompt to LLM for follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 773}
{"timestamp": "2025-07-01 07:36:53,373", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,375", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "LLM response length: 330", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 775}
{"timestamp": "2025-07-01 07:36:53,375", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Parsed 3 questions from LLM response", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 779}
{"timestamp": "2025-07-01 07:36:53,377", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Generated 3 contextual follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 782}
{"timestamp": "2025-07-01 07:36:53,377", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83c\udfaf Generated 3 suggested questions", "module": "conversation_nodes", "function": "generate_response", "line": 339}
{"timestamp": "2025-07-01 07:36:53,377", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Response generated without search results", "module": "conversation_nodes", "function": "generate_response", "line": 354}
{"timestamp": "2025-07-01 07:36:53,377", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 07:36:53,378", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=4", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 07:36:53,384", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 6de94747-1d16-412b-a0e2-38da559ebc2c, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 07:36:53,384", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "Processed message for thread 6de94747-1d16-412b-a0e2-38da559ebc2c", "module": "conversation_manager", "function": "process_user_message", "line": 74}
