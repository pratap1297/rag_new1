{"timestamp": "2025-06-16 11:21:00,389", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:21:00,396", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:21:00,397", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:21:00,400", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:21:00,402", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:21:00,416", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:21:00,417", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:21:00,422", "level": "INFO", "logger": "root", "message": "Created new FAISS index with dimension 384", "module": "faiss_store", "function": "_create_new_index", "line": 141}
{"timestamp": "2025-06-16 11:21:00,423", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 384", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:21:00,425", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-06-16 11:21:01,398", "level": "INFO", "logger": "root", "message": "Loaded SentenceTransformer model: sentence-transformers/all-MiniLM-L6-v2", "module": "embedder", "function": "_load_model", "line": 47}
{"timestamp": "2025-06-16 11:21:01,415", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: sentence-transformers", "module": "embedder", "function": "__init__", "line": 153}
{"timestamp": "2025-06-16 11:21:01,416", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-06-16 11:21:01,417", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['ingestion_engine', 'json_store', 'metadata_store', 'servicenow_integration', 'log_store', 'faiss_store', 'query_engine', 'reranker', 'llm_client', 'embedder', 'query_enhancer', 'config_manager', 'chunker']}", "module": "system_init", "function": "log_system_info", "line": 313}
{"timestamp": "2025-06-16 11:21:01,599", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-06-16 11:21:01,599", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 59}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking: size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 38}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 84}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Excel processor registered without Azure AI support", "module": "ingestion_engine", "function": "_register_excel_processor", "line": 55}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized", "module": "ingestion_engine", "function": "__init__", "line": 29}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "Looking for existing vectors for file_path: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx, doc_path: facility_managers_2024.xlsx, filename: None", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 166}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "root", "message": "No existing vectors found for file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 217}
{"timestamp": "2025-06-16 11:21:01,820", "level": "INFO", "logger": "ExcelProcessor", "message": "Processing Excel file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx", "module": "excel_processor", "function": "process", "line": 99}
{"timestamp": "2025-06-16 11:21:01,844", "level": "INFO", "logger": "ExcelProcessor", "message": "Successfully processed Excel file with 3 sheets, 0 embedded objects, 0 images", "module": "excel_processor", "function": "process", "line": 160}
{"timestamp": "2025-06-16 11:21:02,334", "level": "INFO", "logger": "root", "message": "Saved FAISS index and metadata", "module": "faiss_store", "function": "save_index", "line": 493}
{"timestamp": "2025-06-16 11:21:02,335", "level": "INFO", "logger": "root", "message": "Added 1 vectors to FAISS index", "module": "faiss_store", "function": "add_vectors", "line": 226}
{"timestamp": "2025-06-16 11:21:02,335", "level": "INFO", "logger": "root", "message": "Successfully ingested file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx (1 chunks)", "module": "ingestion_engine", "function": "ingest_file", "line": 135}
{"timestamp": "2025-06-16 11:23:17,038", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:23:17,046", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:23:17,047", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:23:17,047", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:23:17,050", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:23:17,052", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:23:17,052", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:23:17,095", "level": "INFO", "logger": "root", "message": "Loaded existing FAISS index with 1 vectors", "module": "faiss_store", "function": "_initialize_index", "line": 51}
{"timestamp": "2025-06-16 11:23:17,097", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 384", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:23:17,099", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-06-16 11:23:18,342", "level": "INFO", "logger": "root", "message": "Loaded SentenceTransformer model: sentence-transformers/all-MiniLM-L6-v2", "module": "embedder", "function": "_load_model", "line": 47}
{"timestamp": "2025-06-16 11:23:18,342", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: sentence-transformers", "module": "embedder", "function": "__init__", "line": 153}
{"timestamp": "2025-06-16 11:23:18,342", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-06-16 11:23:18,355", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['chunker', 'llm_client', 'config_manager', 'faiss_store', 'query_engine', 'ingestion_engine', 'servicenow_integration', 'json_store', 'embedder', 'metadata_store', 'query_enhancer', 'reranker', 'log_store']}", "module": "system_init", "function": "log_system_info", "line": 313}
{"timestamp": "2025-06-16 11:23:18,534", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-06-16 11:23:18,534", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-06-16 11:23:18,762", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 59}
{"timestamp": "2025-06-16 11:23:18,762", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking: size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 38}
{"timestamp": "2025-06-16 11:23:18,762", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 84}
{"timestamp": "2025-06-16 11:23:18,763", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Excel processor registered without Azure AI support", "module": "ingestion_engine", "function": "_register_excel_processor", "line": 55}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized", "module": "ingestion_engine", "function": "__init__", "line": 29}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Looking for existing vectors for file_path: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx, doc_path: facility_managers_2024.xlsx, filename: None", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 166}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Found matching vector 0: doc_path match: facility_managers_2024.xlsx", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 208}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Found 1 existing vectors", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 211}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Saved FAISS index and metadata", "module": "faiss_store", "function": "save_index", "line": 493}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Cleaned up 1 deleted vectors", "module": "faiss_store", "function": "_cleanup_deleted_vectors", "line": 106}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Deleted 1 vectors", "module": "faiss_store", "function": "delete_vectors", "line": 414}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "root", "message": "Deleted 1 old vectors for file update", "module": "ingestion_engine", "function": "_handle_existing_file", "line": 214}
{"timestamp": "2025-06-16 11:23:18,764", "level": "INFO", "logger": "ExcelProcessor", "message": "Processing Excel file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx", "module": "excel_processor", "function": "process", "line": 99}
{"timestamp": "2025-06-16 11:23:18,780", "level": "INFO", "logger": "ExcelProcessor", "message": "Successfully processed Excel file with 3 sheets, 0 embedded objects, 0 images", "module": "excel_processor", "function": "process", "line": 160}
{"timestamp": "2025-06-16 11:23:18,872", "level": "INFO", "logger": "root", "message": "Saved FAISS index and metadata", "module": "faiss_store", "function": "save_index", "line": 493}
{"timestamp": "2025-06-16 11:23:18,873", "level": "INFO", "logger": "root", "message": "Added 1 vectors to FAISS index", "module": "faiss_store", "function": "add_vectors", "line": 226}
{"timestamp": "2025-06-16 11:23:18,874", "level": "INFO", "logger": "root", "message": "Successfully ingested file: D:\\Projects-D\\pepsi-final2\\document_generator\\test_data\\Facility_Managers_2024.xlsx (1 chunks)", "module": "ingestion_engine", "function": "ingest_file", "line": 135}
{"timestamp": "2025-06-16 11:23:18,874", "level": "INFO", "logger": "root", "message": "Replaced 1 old vectors for updated file", "module": "ingestion_engine", "function": "ingest_file", "line": 137}
{"timestamp": "2025-06-16 11:26:34,619", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:26:34,621", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:26:34,621", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:26:34,621", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:26:34,623", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:26:34,625", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:26:34,625", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:26:34,636", "level": "INFO", "logger": "root", "message": "Loaded existing FAISS index with 1 vectors", "module": "faiss_store", "function": "_initialize_index", "line": 51}
{"timestamp": "2025-06-16 11:26:34,636", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 384", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:26:34,639", "level": "ERROR", "logger": "root", "message": "\u274c RAG System initialization failed: Unsupported embedding provider: azure", "module": "system_init", "function": "initialize_system", "line": 293}
{"timestamp": "2025-06-16 11:30:26,644", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:30:26,644", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:30:26,644", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:30:26,651", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:30:26,652", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:30:26,654", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:30:26,654", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:30:26,676", "level": "INFO", "logger": "root", "message": "Loaded existing FAISS index with 1 vectors", "module": "faiss_store", "function": "_initialize_index", "line": 51}
{"timestamp": "2025-06-16 11:30:26,677", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 1024", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:30:27,253", "level": "INFO", "logger": "root", "message": "Loaded Cohere client with model: embed-english-v3.0", "module": "embedder", "function": "_load_client", "line": 96}
{"timestamp": "2025-06-16 11:30:27,349", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 401 Unauthorized\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-06-16 11:30:27,396", "level": "ERROR", "logger": "root", "message": "\u274c RAG System initialization failed: Failed to initialize Cohere client: status_code: 401, body: {'message': 'invalid api token'}", "module": "system_init", "function": "initialize_system", "line": 293}
{"timestamp": "2025-06-16 11:40:16,142", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-06-16 11:40:16,145", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-06-16 11:40:16,145", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-06-16 11:40:16,146", "level": "WARNING", "logger": "root", "message": "LLM API key not configured. Some features may not work.", "module": "system_init", "function": "validate_system_requirements", "line": 125}
{"timestamp": "2025-06-16 11:40:16,147", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-06-16 11:40:16,149", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-06-16 11:40:16,149", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-06-16 11:40:16,164", "level": "INFO", "logger": "root", "message": "Loaded existing FAISS index with 1 vectors", "module": "faiss_store", "function": "_initialize_index", "line": 51}
{"timestamp": "2025-06-16 11:40:16,165", "level": "INFO", "logger": "root", "message": "FAISS store initialized with dimension 1024", "module": "faiss_store", "function": "__init__", "line": 41}
{"timestamp": "2025-06-16 11:40:16,730", "level": "INFO", "logger": "root", "message": "Loaded Cohere client with model: embed-english-v3.0", "module": "embedder", "function": "_load_client", "line": 96}
{"timestamp": "2025-06-16 11:40:16,951", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.cohere.com/v1/embed \"HTTP/1.1 401 Unauthorized\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-06-16 11:40:16,954", "level": "ERROR", "logger": "root", "message": "\u274c RAG System initialization failed: Failed to initialize Cohere client: status_code: 401, body: {'message': 'invalid api token'}", "module": "system_init", "function": "initialize_system", "line": 293}
{"timestamp": "2025-07-01 07:15:01,783", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 07:15:01,808", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 07:15:01,810", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 07:15:01,812", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 07:15:01,823", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 07:15:01,825", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 07:15:03,156", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:03,170", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:03,173", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 07:15:03,174", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 07:15:03,535", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 07:15:03,537", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '1bad8219-564b-11f0-a409-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 07:15:03,612", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 07:15:02 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 07:15:03,616", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 07:15:03,616", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 07:15:03,947", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 07:15:03,950", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 07:15:03,951", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 07:15:03,952", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['ingestion_engine', 'ingestion_debugger', 'ingestion_verifier', 'llm_client', 'vector_store', 'chunker', 'reranker', 'embedder', 'config_manager', 'log_store', 'json_store', 'query_enhancer', 'query_engine', 'metadata_store', 'servicenow_integration', 'faiss_store', 'conversation_manager', 'verified_ingestion_engine']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 07:15:04,574", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model memory manager initialized - Max memory: 2048MB, Idle timeout: 300s", "module": "model_memory_manager", "function": "__init__", "line": 95}
{"timestamp": "2025-07-01 07:15:04,575", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Loading model: semantic_chunker_all-MiniLM-L6-v2", "module": "model_memory_manager", "function": "get_model", "line": 117}
{"timestamp": "2025-07-01 07:15:04,575", "level": "INFO", "logger": "root", "message": "Loading sentence transformer: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "load_model", "line": 340}
{"timestamp": "2025-07-01 07:15:04,577", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-07-01 07:15:04,577", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-07-01 07:15:06,444", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 loaded in 1.87s. Current memory: 515.52MB", "module": "model_memory_manager", "function": "get_model", "line": 144}
{"timestamp": "2025-07-01 07:15:06,445", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with memory-managed model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 345}
{"timestamp": "2025-07-01 07:15:06,445", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking (model loads on demand): size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 47}
{"timestamp": "2025-07-01 07:15:06,448", "level": "INFO", "logger": "root", "message": "Progress tracker initialized", "module": "progress_tracker", "function": "__init__", "line": 172}
{"timestamp": "2025-07-01 07:15:06,448", "level": "INFO", "logger": "root", "message": "DEBUG: Created processor config with keys: ['chunk_size', 'chunk_overlap', 'supported_formats', 'max_file_size_mb', 'batch_size', 'timeout', 'file_timeout']", "module": "ingestion_engine", "function": "__init__", "line": 45}
{"timestamp": "2025-07-01 07:15:06,448", "level": "INFO", "logger": "root", "message": "Azure AI config added to processor config", "module": "ingestion_engine", "function": "__init__", "line": 54}
{"timestamp": "2025-07-01 07:15:06,450", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 85}
{"timestamp": "2025-07-01 07:15:06,450", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,450", "level": "INFO", "logger": "root", "message": "Extracted Azure AI config from general config", "module": "pdf_processor", "function": "create_pdf_processor", "line": 82}
{"timestamp": "2025-07-01 07:15:06,513", "level": "INFO", "logger": "rag_system.src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 07:15:06,513", "level": "INFO", "logger": "root", "message": "Azure AI client created successfully for PDF processing", "module": "pdf_processor", "function": "create_pdf_processor", "line": 93}
{"timestamp": "2025-07-01 07:15:06,513", "level": "INFO", "logger": "root", "message": "Azure CV endpoint: https://computervision1298.cognitiveservices.azure...", "module": "pdf_processor", "function": "create_pdf_processor", "line": 94}
{"timestamp": "2025-07-01 07:15:06,514", "level": "INFO", "logger": "root", "message": "Using EnhancedPDFProcessor with Azure AI integration", "module": "pdf_processor", "function": "create_pdf_processor", "line": 106}
{"timestamp": "2025-07-01 07:15:06,514", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,514", "level": "INFO", "logger": "WordProcessor", "message": "Word processor initialized", "module": "word_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 07:15:06,514", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: WordProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "ImageProcessor", "message": "Image processor initialized", "module": "image_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ImageProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "ServiceNowProcessor", "message": "ServiceNow processor initialized", "module": "servicenow_processor", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ServiceNowProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "TextProcessor", "message": "Text processor initialized", "module": "text_processor", "function": "__init__", "line": 30}
{"timestamp": "2025-07-01 07:15:06,515", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: TextProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,518", "level": "INFO", "logger": "rag_system.src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 07:15:06,519", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 07:15:06,519", "level": "INFO", "logger": "root", "message": "Enhanced PDF Processor with Azure CV registered successfully", "module": "ingestion_engine", "function": "__init__", "line": 73}
{"timestamp": "2025-07-01 07:15:06,521", "level": "INFO", "logger": "root", "message": "Processor registry initialized with 7 processors", "module": "ingestion_engine", "function": "__init__", "line": 77}
{"timestamp": "2025-07-01 07:15:06,521", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized with managed metadata", "module": "ingestion_engine", "function": "__init__", "line": 89}
{"timestamp": "2025-07-01 07:15:06,584", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:06,586", "level": "INFO", "logger": "root", "message": "\ud83d\udd0d Using processor: TextProcessor for C:\\Users\\JAIDEE~2\\AppData\\Local\\Temp\\tmpvr5jvggn.txt", "module": "ingestion_engine", "function": "_extract_text", "line": 734}
{"timestamp": "2025-07-01 07:15:06,588", "level": "INFO", "logger": "root", "message": "\ud83d\udd0d Using processor: TextProcessor for C:\\Users\\JAIDEE~2\\AppData\\Local\\Temp\\tmpvr5jvggn.txt", "module": "ingestion_engine", "function": "_extract_text", "line": 746}
{"timestamp": "2025-07-01 07:15:06,589", "level": "INFO", "logger": "TextProcessor", "message": "Processing text file: C:\\Users\\JAIDEE~2\\AppData\\Local\\Temp\\tmpvr5jvggn.txt", "module": "text_processor", "function": "process", "line": 66}
{"timestamp": "2025-07-01 07:15:06,591", "level": "INFO", "logger": "root", "message": "\u2705 Processor succeeded, chunks: 1", "module": "ingestion_engine", "function": "_extract_text", "line": 754}
{"timestamp": "2025-07-01 07:15:06,591", "level": "INFO", "logger": "root", "message": "   Processing time: 0.00s", "module": "ingestion_engine", "function": "_extract_text", "line": 755}
{"timestamp": "2025-07-01 07:15:06,593", "level": "INFO", "logger": "root", "message": "Using 1 chunks from processor", "module": "ingestion_engine", "function": "ingest_file", "line": 326}
{"timestamp": "2025-07-01 07:15:06,610", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '584'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '1d8251f9-564b-11f0-9a5a-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 07:15:06,663", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 07:15:05 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 07:15:06,672", "level": "WARNING", "logger": "root", "message": "Flattening nested metadata structure - this should be avoided in future", "module": "metadata_manager", "function": "normalize", "line": 205}
{"timestamp": "2025-07-01 07:15:06,676", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'file_size' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,678", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'content_type' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,678", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'original_filename' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,679", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'filename' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,679", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'upload_source' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,679", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'upload_timestamp' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,680", "level": "WARNING", "logger": "root", "message": "Skipping nested key 'description' - conflicts with top-level key", "module": "metadata_manager", "function": "normalize", "line": 213}
{"timestamp": "2025-07-01 07:15:06,680", "level": "INFO", "logger": "root", "message": "Removing conflicting key 'file_name', keeping 'filename'", "module": "metadata_manager", "function": "normalize", "line": 227}
{"timestamp": "2025-07-01 07:15:06,680", "level": "INFO", "logger": "root", "message": "Removing conflicting key 'content', keeping 'text'", "module": "metadata_manager", "function": "normalize", "line": 227}
{"timestamp": "2025-07-01 07:15:06,930", "level": "INFO", "logger": "httpx", "message": "HTTP Request: PUT http://localhost:6333/collections/rag_documents/points?wait=true \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:06,932", "level": "INFO", "logger": "root", "message": "Added 1 vectors to Qdrant", "module": "qdrant_store", "function": "add_vectors", "line": 123}
{"timestamp": "2025-07-01 07:15:06,933", "level": "INFO", "logger": "root", "message": "Successfully ingested file: C:\\Users\\JAIDEE~2\\AppData\\Local\\Temp\\tmpvr5jvggn.txt (1 chunks)", "module": "ingestion_engine", "function": "ingest_file", "line": 519}
{"timestamp": "2025-07-01 07:15:06,940", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:06,963", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Shutting down model memory manager...", "module": "model_memory_manager", "function": "shutdown", "line": 413}
{"timestamp": "2025-07-01 07:15:07,264", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 unloaded. Current memory: 516.59MB", "module": "model_memory_manager", "function": "_unload_model", "line": 260}
{"timestamp": "2025-07-01 07:15:07,566", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model memory manager shutdown complete", "module": "model_memory_manager", "function": "shutdown", "line": 426}
{"timestamp": "2025-07-01 07:15:58,646", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 07:15:58,655", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 07:15:58,656", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 07:15:58,657", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 07:15:58,668", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 07:15:58,669", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 07:15:59,902", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:59,908", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:15:59,910", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 07:15:59,910", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 07:16:00,244", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 07:16:00,245", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '3d7a556d-564b-11f0-93ac-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 07:16:00,391", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 07:16:00 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 07:16:00,397", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 07:16:00,397", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 07:16:00,678", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 07:16:00,680", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 07:16:00,682", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 07:16:00,683", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['ingestion_verifier', 'embedder', 'chunker', 'servicenow_integration', 'config_manager', 'json_store', 'reranker', 'conversation_manager', 'verified_ingestion_engine', 'ingestion_debugger', 'ingestion_engine', 'log_store', 'metadata_store', 'faiss_store', 'llm_client', 'vector_store', 'query_engine', 'query_enhancer']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 07:16:00,693", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:49,729", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 07:36:49,734", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 07:36:49,734", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 07:36:49,736", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 07:36:49,738", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 07:36:49,738", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 07:36:51,361", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:51,368", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:51,370", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 07:36:51,372", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 07:36:51,778", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 07:36:51,780", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '27733afd-564e-11f0-b3b7-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 07:36:51,942", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 07:36:51 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 07:36:51,949", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 07:36:51,949", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 07:36:52,311", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 07:36:52,313", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 07:36:52,324", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 07:36:52,325", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['chunker', 'faiss_store', 'vector_store', 'verified_ingestion_engine', 'ingestion_verifier', 'log_store', 'embedder', 'query_engine', 'llm_client', 'config_manager', 'ingestion_debugger', 'servicenow_integration', 'json_store', 'reranker', 'query_enhancer', 'metadata_store', 'conversation_manager', 'ingestion_engine']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 07:36:52,819", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Initialized Memory checkpointer for state persistence", "module": "conversation_graph", "function": "__init__", "line": 36}
{"timestamp": "2025-07-01 07:36:52,838", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Conversation graph compiled successfully with Memory state persistence", "module": "conversation_graph", "function": "_build_graph", "line": 104}
{"timestamp": "2025-07-01 07:36:52,838", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "ConversationGraph initialized with state persistence", "module": "conversation_graph", "function": "__init__", "line": 41}
{"timestamp": "2025-07-01 07:36:52,839", "level": "WARNING", "logger": "rag_system.src.conversation.conversation_graph", "message": "Checkpointer not available or missing client attribute", "module": "conversation_graph", "function": "list_conversation_threads", "line": 309}
{"timestamp": "2025-07-01 07:36:52,840", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "Conversation cleanup completed: 0 old conversations removed", "module": "conversation_manager", "function": "cleanup_old_conversations", "line": 173}
{"timestamp": "2025-07-01 07:36:52,840", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "Initial conversation cleanup: 0 conversations removed", "module": "conversation_manager", "function": "__init__", "line": 34}
{"timestamp": "2025-07-01 07:36:52,840", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "ConversationManager initialized with LangGraph state persistence and memory management", "module": "conversation_manager", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 07:36:52,842", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Created new conversation state for thread 6de94747-1d16-412b-a0e2-38da559ebc2c", "module": "conversation_graph", "function": "_get_or_create_state", "line": 259}
{"timestamp": "2025-07-01 07:36:52,871", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 07:36:52,872", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 07:36:52,873", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Routing after understanding - intent: None, turn: 1", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 07:36:52,874", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 07:36:52,874", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 07:36:52,886", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 07:36:52,888", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Response generated without search results", "module": "conversation_nodes", "function": "generate_response", "line": 354}
{"timestamp": "2025-07-01 07:36:52,889", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 07:36:52,889", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=None, turns=2", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 07:36:52,891", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 6de94747-1d16-412b-a0e2-38da559ebc2c, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 07:36:52,891", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "Started/retrieved conversation for thread: 6de94747-1d16-412b-a0e2-38da559ebc2c", "module": "conversation_manager", "function": "start_conversation", "line": 53}
{"timestamp": "2025-07-01 07:36:52,892", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 6de94747-1d16-412b-a0e2-38da559ebc2c", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 07:36:52,895", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 07:36:52,895", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 07:36:52,898", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Conversation has history - treating with partial context", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 424}
{"timestamp": "2025-07-01 07:36:52,898", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Building contextual query from: 'How many routers are in the system?'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 07:36:52,899", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Enhanced query to: 'How many routers are in the system? (context: )'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 07:36:52,899", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'How many routers are in the system? (context: )'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 07:36:52,900", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['many', 'routers', 'system']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 07:36:52,901", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 07:36:52,901", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 07:36:52,902", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 3", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 07:36:52,903", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 07:36:52,904", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 07:36:52,904", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'How many routers are in the system? (context: )'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 07:36:52,905", "level": "INFO", "logger": "root", "message": "Query type detected: aggregation", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 07:36:52,959", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:52,966", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:52,984", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,012", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,018", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,020", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Search strategy 2: Original query: 'How many routers are in the system?'", "module": "conversation_nodes", "function": "search_knowledge", "line": 182}
{"timestamp": "2025-07-01 07:36:53,020", "level": "INFO", "logger": "root", "message": "Query type detected: aggregation", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 07:36:53,025", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,030", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,046", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,053", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,061", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,064", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 07:36:53,072", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'aggregation_results', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 07:36:53,072", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "No sources found in search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 262}
{"timestamp": "2025-07-01 07:36:53,073", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 07:36:53,074", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 07:36:53,074", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Using query engine response directly", "module": "conversation_nodes", "function": "_generate_contextual_response", "line": 513}
{"timestamp": "2025-07-01 07:36:53,076", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83d\ude80 Generating follow-up questions", "module": "conversation_nodes", "function": "generate_response", "line": 337}
{"timestamp": "2025-07-01 07:36:53,076", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83d\udd25 FOLLOW-UP QUESTIONS METHOD CALLED \ud83d\udd25", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 722}
{"timestamp": "2025-07-01 07:36:53,076", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Starting follow-up question generation", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 738}
{"timestamp": "2025-07-01 07:36:53,077", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Built context info with length: 331", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 747}
{"timestamp": "2025-07-01 07:36:53,077", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Sending prompt to LLM for follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 773}
{"timestamp": "2025-07-01 07:36:53,373", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 07:36:53,375", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "LLM response length: 330", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 775}
{"timestamp": "2025-07-01 07:36:53,375", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Parsed 3 questions from LLM response", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 779}
{"timestamp": "2025-07-01 07:36:53,377", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Generated 3 contextual follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 782}
{"timestamp": "2025-07-01 07:36:53,377", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "\ud83c\udfaf Generated 3 suggested questions", "module": "conversation_nodes", "function": "generate_response", "line": 339}
{"timestamp": "2025-07-01 07:36:53,377", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Response generated without search results", "module": "conversation_nodes", "function": "generate_response", "line": 354}
{"timestamp": "2025-07-01 07:36:53,377", "level": "INFO", "logger": "rag_system.src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 07:36:53,378", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=4", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 07:36:53,384", "level": "INFO", "logger": "rag_system.src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 6de94747-1d16-412b-a0e2-38da559ebc2c, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 07:36:53,384", "level": "INFO", "logger": "rag_system.src.conversation.conversation_manager", "message": "Processed message for thread 6de94747-1d16-412b-a0e2-38da559ebc2c", "module": "conversation_manager", "function": "process_user_message", "line": 74}
{"timestamp": "2025-07-01 10:40:27,840", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 10:40:27,844", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 10:40:27,844", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 10:40:27,845", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 10:40:27,848", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 10:40:27,848", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 10:40:29,175", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 10:40:29,193", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 10:40:29,195", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 10:40:29,195", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 10:40:29,202", "level": "ERROR", "logger": "root", "message": "\u274c RAG System initialization failed: Azure endpoint not provided. Set AZURE_EMBEDDINGS_ENDPOINT environment variable.", "module": "system_init", "function": "initialize_system", "line": 299}
{"timestamp": "2025-07-01 10:40:52,547", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 10:40:52,560", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 10:40:52,561", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 10:40:52,563", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 10:40:52,564", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 10:40:52,565", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 10:40:53,735", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 10:40:53,740", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 10:40:53,743", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 10:40:53,744", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 10:40:54,090", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 10:40:54,090", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': 'dd2e5a12-5667-11f0-9f65-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 10:40:54,200", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 10:40:53 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 10:40:54,205", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 10:40:54,206", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 10:40:54,514", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 10:40:54,516", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 10:40:54,518", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 10:40:54,518", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['reranker', 'chunker', 'metadata_store', 'config_manager', 'query_engine', 'faiss_store', 'verified_ingestion_engine', 'log_store', 'vector_store', 'llm_client', 'conversation_manager', 'json_store', 'query_enhancer', 'servicenow_integration', 'ingestion_verifier', 'embedder', 'ingestion_debugger', 'ingestion_engine']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 11:42:38,658", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 11:42:38,661", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 11:42:38,662", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 11:42:38,664", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 11:42:38,667", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 11:42:38,668", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 11:42:40,137", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 11:42:40,143", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 11:42:40,148", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 11:42:40,150", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 11:42:40,537", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 11:42:40,539", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '7e6585e1-5670-11f0-8566-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 11:42:40,669", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 11:42:40 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 11:42:40,674", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 11:42:40,679", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 11:42:41,102", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 11:42:41,104", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 11:42:41,106", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 11:42:41,107", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['query_engine', 'metadata_store', 'json_store', 'servicenow_integration', 'log_store', 'vector_store', 'verified_ingestion_engine', 'chunker', 'ingestion_engine', 'ingestion_debugger', 'llm_client', 'faiss_store', 'conversation_manager', 'embedder', 'ingestion_verifier', 'config_manager', 'query_enhancer', 'reranker']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 11:42:41,881", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model memory manager initialized - Max memory: 2048MB, Idle timeout: 300s", "module": "model_memory_manager", "function": "__init__", "line": 95}
{"timestamp": "2025-07-01 11:42:41,881", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Loading model: semantic_chunker_all-MiniLM-L6-v2", "module": "model_memory_manager", "function": "get_model", "line": 117}
{"timestamp": "2025-07-01 11:42:41,882", "level": "INFO", "logger": "root", "message": "Loading sentence transformer: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "load_model", "line": 340}
{"timestamp": "2025-07-01 11:42:41,882", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-07-01 11:42:41,883", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-07-01 11:42:44,452", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 loaded in 2.57s. Current memory: 516.89MB", "module": "model_memory_manager", "function": "get_model", "line": 144}
{"timestamp": "2025-07-01 11:42:44,452", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with memory-managed model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 345}
{"timestamp": "2025-07-01 11:42:44,452", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking (model loads on demand): size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 47}
{"timestamp": "2025-07-01 11:42:44,469", "level": "INFO", "logger": "root", "message": "Progress tracker initialized", "module": "progress_tracker", "function": "__init__", "line": 172}
{"timestamp": "2025-07-01 11:42:44,469", "level": "INFO", "logger": "root", "message": "DEBUG: Created processor config with keys: ['chunk_size', 'chunk_overlap', 'supported_formats', 'max_file_size_mb', 'batch_size', 'timeout', 'file_timeout']", "module": "ingestion_engine", "function": "__init__", "line": 45}
{"timestamp": "2025-07-01 11:42:44,470", "level": "INFO", "logger": "root", "message": "Azure AI config added to processor config", "module": "ingestion_engine", "function": "__init__", "line": 54}
{"timestamp": "2025-07-01 11:42:44,470", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 85}
{"timestamp": "2025-07-01 11:42:44,470", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:42:44,471", "level": "INFO", "logger": "root", "message": "Extracted Azure AI config from general config", "module": "pdf_processor", "function": "create_pdf_processor", "line": 82}
{"timestamp": "2025-07-01 11:42:44,578", "level": "INFO", "logger": "rag_system.src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 11:42:44,578", "level": "INFO", "logger": "root", "message": "Azure AI client created successfully for PDF processing", "module": "pdf_processor", "function": "create_pdf_processor", "line": 93}
{"timestamp": "2025-07-01 11:42:44,578", "level": "INFO", "logger": "root", "message": "Azure CV endpoint: https://computervision1298.cognitiveservices.azure...", "module": "pdf_processor", "function": "create_pdf_processor", "line": 94}
{"timestamp": "2025-07-01 11:42:44,579", "level": "INFO", "logger": "root", "message": "Using EnhancedPDFProcessor with Azure AI integration", "module": "pdf_processor", "function": "create_pdf_processor", "line": 106}
{"timestamp": "2025-07-01 11:42:44,579", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:42:44,579", "level": "INFO", "logger": "WordProcessor", "message": "Word processor initialized", "module": "word_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 11:42:44,585", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: WordProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:42:44,585", "level": "INFO", "logger": "ImageProcessor", "message": "Image processor initialized", "module": "image_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 11:42:44,589", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ImageProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:42:44,589", "level": "INFO", "logger": "ServiceNowProcessor", "message": "ServiceNow processor initialized", "module": "servicenow_processor", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 11:42:44,590", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ServiceNowProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:42:44,591", "level": "INFO", "logger": "TextProcessor", "message": "Text processor initialized", "module": "text_processor", "function": "__init__", "line": 30}
{"timestamp": "2025-07-01 11:42:44,591", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: TextProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:42:44,595", "level": "INFO", "logger": "rag_system.src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 11:42:44,596", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:42:44,596", "level": "INFO", "logger": "root", "message": "Enhanced PDF Processor with Azure CV registered successfully", "module": "ingestion_engine", "function": "__init__", "line": 73}
{"timestamp": "2025-07-01 11:42:44,596", "level": "INFO", "logger": "root", "message": "Processor registry initialized with 7 processors", "module": "ingestion_engine", "function": "__init__", "line": 77}
{"timestamp": "2025-07-01 11:42:44,596", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized with managed metadata", "module": "ingestion_engine", "function": "__init__", "line": 89}
{"timestamp": "2025-07-01 11:42:44,604", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '236'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '80d1c7df-5670-11f0-aaf7-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 11:42:44,696", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 11:42:44 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 11:42:44,704", "level": "INFO", "logger": "root", "message": "Removing conflicting key 'content', keeping 'text'", "module": "metadata_manager", "function": "normalize", "line": 227}
{"timestamp": "2025-07-01 11:42:44,731", "level": "INFO", "logger": "httpx", "message": "HTTP Request: PUT http://localhost:6333/collections/rag_documents/points?wait=true \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 11:42:44,733", "level": "INFO", "logger": "root", "message": "Added 1 vectors to Qdrant", "module": "qdrant_store", "function": "add_vectors", "line": 123}
{"timestamp": "2025-07-01 11:42:44,734", "level": "INFO", "logger": "root", "message": "Successfully ingested text content (1 chunks)", "module": "ingestion_engine", "function": "ingest_text", "line": 637}
{"timestamp": "2025-07-01 11:42:44,735", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Shutting down model memory manager...", "module": "model_memory_manager", "function": "shutdown", "line": 413}
{"timestamp": "2025-07-01 11:42:45,076", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 unloaded. Current memory: 517.94MB", "module": "model_memory_manager", "function": "_unload_model", "line": 260}
{"timestamp": "2025-07-01 11:42:45,405", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model memory manager shutdown complete", "module": "model_memory_manager", "function": "shutdown", "line": 426}
{"timestamp": "2025-07-01 11:44:10,539", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 11:44:10,542", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 11:44:10,544", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 11:44:10,545", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 11:44:10,556", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 11:44:10,557", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 11:44:11,991", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 11:44:12,002", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 11:44:12,003", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 11:44:12,004", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 11:44:12,442", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 11:44:12,444", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': 'b52d2b07-5670-11f0-a424-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 11:44:12,575", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 11:44:11 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 11:44:12,580", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 11:44:12,580", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 11:44:12,930", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 11:44:12,932", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 11:44:12,936", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 11:44:14,264", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['metadata_store', 'embedder', 'reranker', 'chunker', 'query_enhancer', 'log_store', 'ingestion_debugger', 'json_store', 'servicenow_integration', 'ingestion_engine', 'faiss_store', 'vector_store', 'conversation_manager', 'query_engine', 'llm_client', 'ingestion_verifier', 'config_manager', 'verified_ingestion_engine']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 11:44:14,891", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model memory manager initialized - Max memory: 2048MB, Idle timeout: 300s", "module": "model_memory_manager", "function": "__init__", "line": 95}
{"timestamp": "2025-07-01 11:44:14,892", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Loading model: semantic_chunker_all-MiniLM-L6-v2", "module": "model_memory_manager", "function": "get_model", "line": 117}
{"timestamp": "2025-07-01 11:44:14,892", "level": "INFO", "logger": "root", "message": "Loading sentence transformer: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "load_model", "line": 340}
{"timestamp": "2025-07-01 11:44:14,894", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-07-01 11:44:14,894", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-07-01 11:44:16,394", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 loaded in 1.50s. Current memory: 516.59MB", "module": "model_memory_manager", "function": "get_model", "line": 144}
{"timestamp": "2025-07-01 11:44:16,400", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with memory-managed model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 345}
{"timestamp": "2025-07-01 11:44:16,400", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking (model loads on demand): size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 47}
{"timestamp": "2025-07-01 11:44:16,405", "level": "INFO", "logger": "root", "message": "Progress tracker initialized", "module": "progress_tracker", "function": "__init__", "line": 172}
{"timestamp": "2025-07-01 11:44:16,405", "level": "INFO", "logger": "root", "message": "DEBUG: Created processor config with keys: ['chunk_size', 'chunk_overlap', 'supported_formats', 'max_file_size_mb', 'batch_size', 'timeout', 'file_timeout']", "module": "ingestion_engine", "function": "__init__", "line": 45}
{"timestamp": "2025-07-01 11:44:16,406", "level": "INFO", "logger": "root", "message": "Azure AI config added to processor config", "module": "ingestion_engine", "function": "__init__", "line": 54}
{"timestamp": "2025-07-01 11:44:16,406", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 85}
{"timestamp": "2025-07-01 11:44:16,406", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:44:16,407", "level": "INFO", "logger": "root", "message": "Extracted Azure AI config from general config", "module": "pdf_processor", "function": "create_pdf_processor", "line": 82}
{"timestamp": "2025-07-01 11:44:16,475", "level": "INFO", "logger": "rag_system.src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 11:44:16,477", "level": "INFO", "logger": "root", "message": "Azure AI client created successfully for PDF processing", "module": "pdf_processor", "function": "create_pdf_processor", "line": 93}
{"timestamp": "2025-07-01 11:44:16,479", "level": "INFO", "logger": "root", "message": "Azure CV endpoint: https://computervision1298.cognitiveservices.azure...", "module": "pdf_processor", "function": "create_pdf_processor", "line": 94}
{"timestamp": "2025-07-01 11:44:16,479", "level": "INFO", "logger": "root", "message": "Using EnhancedPDFProcessor with Azure AI integration", "module": "pdf_processor", "function": "create_pdf_processor", "line": 106}
{"timestamp": "2025-07-01 11:44:16,479", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:44:16,480", "level": "INFO", "logger": "WordProcessor", "message": "Word processor initialized", "module": "word_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 11:44:16,480", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: WordProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:44:16,480", "level": "INFO", "logger": "ImageProcessor", "message": "Image processor initialized", "module": "image_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 11:44:16,480", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ImageProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:44:16,481", "level": "INFO", "logger": "ServiceNowProcessor", "message": "ServiceNow processor initialized", "module": "servicenow_processor", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 11:44:16,481", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: ServiceNowProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:44:16,481", "level": "INFO", "logger": "TextProcessor", "message": "Text processor initialized", "module": "text_processor", "function": "__init__", "line": 30}
{"timestamp": "2025-07-01 11:44:16,482", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: TextProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:44:16,485", "level": "INFO", "logger": "rag_system.src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 11:44:16,485", "level": "INFO", "logger": "rag_system.src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 11:44:16,486", "level": "INFO", "logger": "root", "message": "Enhanced PDF Processor with Azure CV registered successfully", "module": "ingestion_engine", "function": "__init__", "line": 73}
{"timestamp": "2025-07-01 11:44:16,486", "level": "INFO", "logger": "root", "message": "Processor registry initialized with 7 processors", "module": "ingestion_engine", "function": "__init__", "line": 77}
{"timestamp": "2025-07-01 11:44:16,486", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized with managed metadata", "module": "ingestion_engine", "function": "__init__", "line": 89}
{"timestamp": "2025-07-01 11:44:16,487", "level": "INFO", "logger": "root", "message": "\ud83d\udd0d Detected JSON content in ingest_text, attempting processor route", "module": "ingestion_engine", "function": "ingest_text", "line": 562}
{"timestamp": "2025-07-01 11:44:16,488", "level": "INFO", "logger": "root", "message": "\ud83c\udfaf Detected ServiceNow JSON, using processor", "module": "ingestion_engine", "function": "ingest_text", "line": 586}
{"timestamp": "2025-07-01 11:44:16,494", "level": "INFO", "logger": "root", "message": "\ud83d\udce6 Using processor: ServiceNowProcessor for JSON content", "module": "ingestion_engine", "function": "ingest_text", "line": 598}
{"timestamp": "2025-07-01 11:44:16,495", "level": "INFO", "logger": "ServiceNowProcessor", "message": "\ud83c\udfab Starting ServiceNow/JSON processing: C:\\Users\\JAIDEE~2\\AppData\\Local\\Temp\\tmplfdedc0j.json", "module": "servicenow_processor", "function": "process", "line": 49}
{"timestamp": "2025-07-01 11:44:16,495", "level": "INFO", "logger": "ServiceNowProcessor", "message": "\ud83c\udfab File type: JSON | File size: 186 bytes", "module": "servicenow_processor", "function": "process", "line": 50}
{"timestamp": "2025-07-01 11:44:16,496", "level": "INFO", "logger": "ServiceNowProcessor", "message": "\ud83c\udfab Processor: ServiceNowProcessor", "module": "servicenow_processor", "function": "process", "line": 51}
{"timestamp": "2025-07-01 11:44:16,505", "level": "INFO", "logger": "ServiceNowProcessor", "message": "\ud83c\udfab JSON Structure Analysis:", "module": "servicenow_processor", "function": "process", "line": 70}
{"timestamp": "2025-07-01 11:44:16,505", "level": "INFO", "logger": "ServiceNowProcessor", "message": "  - Data type: dict", "module": "servicenow_processor", "function": "process", "line": 71}
{"timestamp": "2025-07-01 11:44:16,506", "level": "INFO", "logger": "ServiceNowProcessor", "message": "  - Total records: 1", "module": "servicenow_processor", "function": "process", "line": 72}
{"timestamp": "2025-07-01 11:44:16,506", "level": "INFO", "logger": "ServiceNowProcessor", "message": "  - Structure depth: 3", "module": "servicenow_processor", "function": "process", "line": 73}
{"timestamp": "2025-07-01 11:44:16,506", "level": "INFO", "logger": "ServiceNowProcessor", "message": "  - Field count: 1", "module": "servicenow_processor", "function": "process", "line": 74}
{"timestamp": "2025-07-01 11:44:16,507", "level": "INFO", "logger": "ServiceNowProcessor", "message": "  - ServiceNow detected: No", "module": "servicenow_processor", "function": "process", "line": 75}
{"timestamp": "2025-07-01 11:44:16,507", "level": "INFO", "logger": "ServiceNowProcessor", "message": "\u2705 ServiceNow/JSON processing completed in 0.01s", "module": "servicenow_processor", "function": "process", "line": 109}
{"timestamp": "2025-07-01 11:44:16,507", "level": "INFO", "logger": "ServiceNowProcessor", "message": "\ud83c\udfab Final Result:", "module": "servicenow_processor", "function": "process", "line": 110}
{"timestamp": "2025-07-01 11:44:16,508", "level": "INFO", "logger": "ServiceNowProcessor", "message": "  - Records processed: 1", "module": "servicenow_processor", "function": "process", "line": 111}
{"timestamp": "2025-07-01 11:44:16,508", "level": "INFO", "logger": "ServiceNowProcessor", "message": "  - Chunks created: 1", "module": "servicenow_processor", "function": "process", "line": 112}
{"timestamp": "2025-07-01 11:44:16,509", "level": "INFO", "logger": "ServiceNowProcessor", "message": "  - Total text length: 131 chars", "module": "servicenow_processor", "function": "process", "line": 113}
{"timestamp": "2025-07-01 11:44:16,510", "level": "INFO", "logger": "root", "message": "\u2705 Processor created 1 logical chunks", "module": "ingestion_engine", "function": "ingest_text", "line": 604}
{"timestamp": "2025-07-01 11:44:16,530", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '224'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': 'b79c83ac-5670-11f0-a5f3-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 11:44:16,631", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 11:44:15 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 11:44:16,636", "level": "INFO", "logger": "root", "message": "Removing conflicting key 'content', keeping 'text'", "module": "metadata_manager", "function": "normalize", "line": 227}
{"timestamp": "2025-07-01 11:44:16,754", "level": "INFO", "logger": "httpx", "message": "HTTP Request: PUT http://localhost:6333/collections/rag_documents/points?wait=true \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 11:44:16,756", "level": "INFO", "logger": "root", "message": "Added 1 vectors to Qdrant", "module": "qdrant_store", "function": "add_vectors", "line": 123}
{"timestamp": "2025-07-01 11:44:16,756", "level": "INFO", "logger": "root", "message": "\u2705 Successfully processed JSON content with ServiceNowProcessor (1 logical chunks)", "module": "ingestion_engine", "function": "ingest_text", "line": 665}
{"timestamp": "2025-07-01 11:44:16,758", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Shutting down model memory manager...", "module": "model_memory_manager", "function": "shutdown", "line": 413}
{"timestamp": "2025-07-01 11:44:17,129", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 unloaded. Current memory: 517.66MB", "module": "model_memory_manager", "function": "_unload_model", "line": 260}
{"timestamp": "2025-07-01 11:44:17,464", "level": "INFO", "logger": "rag_system.src.core.model_memory_manager", "message": "Model memory manager shutdown complete", "module": "model_memory_manager", "function": "shutdown", "line": 426}
{"timestamp": "2025-07-01 15:13:54,005", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 15:13:54,019", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 15:13:54,020", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 15:13:54,021", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 15:13:54,024", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 15:13:54,025", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 15:13:55,628", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:13:55,644", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:13:55,648", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 15:13:55,650", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 15:13:56,096", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 15:13:56,097", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '019e336c-568e-11f0-ab41-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 15:13:56,241", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 15:13:55 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 15:13:56,248", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 15:13:56,248", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 15:13:56,630", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 15:13:56,630", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 15:13:56,643", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 15:13:56,644", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['ingestion_debugger', 'query_enhancer', 'json_store', 'faiss_store', 'verified_ingestion_engine', 'ingestion_verifier', 'llm_client', 'reranker', 'chunker', 'query_engine', 'log_store', 'servicenow_integration', 'metadata_store', 'conversation_manager', 'ingestion_engine', 'embedder', 'vector_store', 'config_manager']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 15:13:56,648", "level": "INFO", "logger": "root", "message": "Setting up monitoring...", "module": "main", "function": "main", "line": 77}
{"timestamp": "2025-07-01 15:13:56,649", "level": "INFO", "logger": "root", "message": "Monitoring setup completed", "module": "setup", "function": "setup_monitoring", "line": 18}
{"timestamp": "2025-07-01 15:13:56,650", "level": "INFO", "logger": "root", "message": "Initializing heartbeat monitor...", "module": "main", "function": "main", "line": 87}
{"timestamp": "2025-07-01 15:13:56,650", "level": "INFO", "logger": "src.monitoring.heartbeat_monitor", "message": "Heartbeat monitor initialized", "module": "heartbeat_monitor", "function": "__init__", "line": 85}
{"timestamp": "2025-07-01 15:13:56,650", "level": "INFO", "logger": "root", "message": "\u2705 Heartbeat monitor initialized successfully", "module": "main", "function": "main", "line": 89}
{"timestamp": "2025-07-01 15:13:56,653", "level": "INFO", "logger": "root", "message": "Initializing folder monitor...", "module": "main", "function": "main", "line": 98}
{"timestamp": "2025-07-01 15:13:56,655", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Loaded folder monitoring config: 0 folders, 60s interval", "module": "folder_monitor", "function": "_load_config", "line": 95}
{"timestamp": "2025-07-01 15:13:56,655", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Folder monitor initialized", "module": "folder_monitor", "function": "__init__", "line": 76}
{"timestamp": "2025-07-01 15:13:56,655", "level": "INFO", "logger": "root", "message": "\u2705 Folder monitor initialized successfully", "module": "main", "function": "main", "line": 101}
{"timestamp": "2025-07-01 15:13:57,067", "level": "INFO", "logger": "root", "message": "Initializing enhanced folder monitor...", "module": "main", "function": "main", "line": 110}
{"timestamp": "2025-07-01 15:13:57,067", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Loaded folder monitoring config: 0 folders, 60s interval", "module": "folder_monitor", "function": "_load_config", "line": 95}
{"timestamp": "2025-07-01 15:13:57,067", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Folder monitor initialized", "module": "folder_monitor", "function": "__init__", "line": 76}
{"timestamp": "2025-07-01 15:13:57,069", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Enhanced folder monitor initialized with pipeline verification", "module": "enhanced_folder_monitor", "function": "__init__", "line": 84}
{"timestamp": "2025-07-01 15:13:57,078", "level": "INFO", "logger": "root", "message": "\u2705 Enhanced folder monitor initialized successfully", "module": "main", "function": "main", "line": 113}
{"timestamp": "2025-07-01 15:13:57,126", "level": "INFO", "logger": "root", "message": "\u2705 Heartbeat monitor registered with API", "module": "main", "function": "main", "line": 122}
{"timestamp": "2025-07-01 15:13:57,127", "level": "INFO", "logger": "root", "message": "\u2705 Folder monitor registered with API", "module": "main", "function": "main", "line": 130}
{"timestamp": "2025-07-01 15:13:57,127", "level": "INFO", "logger": "root", "message": "Creating FastAPI application...", "module": "main", "function": "main", "line": 136}
{"timestamp": "2025-07-01 15:13:57,128", "level": "INFO", "logger": "root", "message": "ResourceManager initialized", "module": "resource_manager", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 15:13:57,128", "level": "INFO", "logger": "root", "message": "Initialized GlobalRAGSystem lifecycle manager", "module": "resource_manager", "function": "__init__", "line": 390}
{"timestamp": "2025-07-01 15:13:57,128", "level": "INFO", "logger": "root", "message": "Starting GlobalRAGSystem...", "module": "resource_manager", "function": "startup", "line": 398}
{"timestamp": "2025-07-01 15:13:57,130", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_main", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:13:57,130", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'main' with 4 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:13:57,149", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_io", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:13:57,149", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'io' with 8 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:13:57,150", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_compute", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:13:57,150", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'compute' with 2 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:13:57,150", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_background", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:13:57,151", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'background' with 2 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:13:57,151", "level": "INFO", "logger": "root", "message": "GlobalRAGSystem startup completed successfully", "module": "resource_manager", "function": "startup", "line": 411}
{"timestamp": "2025-07-01 15:13:57,152", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_api_operations", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:13:57,152", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'api_operations' with 8 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:13:57,152", "level": "INFO", "logger": "root", "message": "\u2705 Heartbeat monitor set in API: <class 'src.monitoring.heartbeat_monitor.HeartbeatMonitor'>", "module": "main", "function": "create_api_app", "line": 227}
{"timestamp": "2025-07-01 15:13:57,153", "level": "INFO", "logger": "root", "message": "\u2705 Folder monitor set in API: <class 'src.monitoring.folder_monitor.FolderMonitor'>", "module": "main", "function": "create_api_app", "line": 240}
{"timestamp": "2025-07-01 15:13:57,278", "level": "INFO", "logger": "src.storage.feedback_store", "message": "Feedback store initialized at: data\\feedback_store.db", "module": "feedback_store", "function": "__init__", "line": 29}
{"timestamp": "2025-07-01 15:13:57,313", "level": "INFO", "logger": "root", "message": "\u2705 Management API routes registered", "module": "main", "function": "create_api_app", "line": 2341}
{"timestamp": "2025-07-01 15:13:57,336", "level": "WARNING", "logger": "root", "message": "\u26a0\ufe0f ServiceNow API routes not available: No module named 'rag_system'", "module": "main", "function": "create_api_app", "line": 2356}
{"timestamp": "2025-07-01 15:13:57,369", "level": "INFO", "logger": "root", "message": "\u2705 Conversation API routes registered", "module": "main", "function": "create_api_app", "line": 2365}
{"timestamp": "2025-07-01 15:13:57,372", "level": "INFO", "logger": "root", "message": "\u2705 Verification API routes registered", "module": "main", "function": "create_api_app", "line": 2373}
{"timestamp": "2025-07-01 15:13:57,375", "level": "INFO", "logger": "root", "message": "\u2705 Enhanced folder monitoring API routes registered", "module": "main", "function": "create_api_app", "line": 2383}
{"timestamp": "2025-07-01 15:13:57,376", "level": "INFO", "logger": "root", "message": "Progress tracker initialized", "module": "progress_tracker", "function": "__init__", "line": 172}
{"timestamp": "2025-07-01 15:13:57,942", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Model memory manager initialized - Max memory: 2048MB, Idle timeout: 300s", "module": "model_memory_manager", "function": "__init__", "line": 95}
{"timestamp": "2025-07-01 15:13:57,942", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Loading model: semantic_chunker_all-MiniLM-L6-v2", "module": "model_memory_manager", "function": "get_model", "line": 117}
{"timestamp": "2025-07-01 15:13:57,943", "level": "INFO", "logger": "root", "message": "Loading sentence transformer: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "load_model", "line": 340}
{"timestamp": "2025-07-01 15:13:57,959", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-07-01 15:13:57,960", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-07-01 15:13:59,585", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 loaded in 1.64s. Current memory: 520.36MB", "module": "model_memory_manager", "function": "get_model", "line": 144}
{"timestamp": "2025-07-01 15:13:59,588", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with memory-managed model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 345}
{"timestamp": "2025-07-01 15:13:59,588", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking (model loads on demand): size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 47}
{"timestamp": "2025-07-01 15:13:59,599", "level": "INFO", "logger": "root", "message": "Progress tracker initialized", "module": "progress_tracker", "function": "__init__", "line": 172}
{"timestamp": "2025-07-01 15:13:59,607", "level": "INFO", "logger": "root", "message": "DEBUG: Created processor config with keys: ['chunk_size', 'chunk_overlap', 'supported_formats', 'max_file_size_mb', 'batch_size', 'timeout', 'file_timeout']", "module": "ingestion_engine", "function": "__init__", "line": 45}
{"timestamp": "2025-07-01 15:13:59,608", "level": "INFO", "logger": "root", "message": "Azure AI config added to processor config", "module": "ingestion_engine", "function": "__init__", "line": 54}
{"timestamp": "2025-07-01 15:13:59,608", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 85}
{"timestamp": "2025-07-01 15:13:59,609", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:13:59,609", "level": "INFO", "logger": "root", "message": "Extracted Azure AI config from general config", "module": "pdf_processor", "function": "create_pdf_processor", "line": 82}
{"timestamp": "2025-07-01 15:13:59,983", "level": "INFO", "logger": "src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 15:13:59,984", "level": "INFO", "logger": "root", "message": "Azure AI client created successfully for PDF processing", "module": "pdf_processor", "function": "create_pdf_processor", "line": 93}
{"timestamp": "2025-07-01 15:13:59,985", "level": "INFO", "logger": "root", "message": "Azure CV endpoint: https://computervision1298.cognitiveservices.azure...", "module": "pdf_processor", "function": "create_pdf_processor", "line": 94}
{"timestamp": "2025-07-01 15:13:59,985", "level": "INFO", "logger": "root", "message": "Using EnhancedPDFProcessor with Azure AI integration", "module": "pdf_processor", "function": "create_pdf_processor", "line": 106}
{"timestamp": "2025-07-01 15:13:59,985", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:13:59,986", "level": "INFO", "logger": "WordProcessor", "message": "Word processor initialized", "module": "word_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 15:13:59,987", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: WordProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:13:59,987", "level": "INFO", "logger": "ImageProcessor", "message": "Image processor initialized", "module": "image_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 15:13:59,987", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ImageProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:13:59,988", "level": "INFO", "logger": "ServiceNowProcessor", "message": "ServiceNow processor initialized", "module": "servicenow_processor", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 15:13:59,988", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ServiceNowProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:13:59,992", "level": "INFO", "logger": "TextProcessor", "message": "Text processor initialized", "module": "text_processor", "function": "__init__", "line": 30}
{"timestamp": "2025-07-01 15:13:59,992", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: TextProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:13:59,995", "level": "INFO", "logger": "src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 15:13:59,996", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:13:59,996", "level": "INFO", "logger": "root", "message": "Enhanced PDF Processor with Azure CV registered successfully", "module": "ingestion_engine", "function": "__init__", "line": 73}
{"timestamp": "2025-07-01 15:13:59,997", "level": "INFO", "logger": "root", "message": "Processor registry initialized with 7 processors", "module": "ingestion_engine", "function": "__init__", "line": 77}
{"timestamp": "2025-07-01 15:13:59,997", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized with managed metadata", "module": "ingestion_engine", "function": "__init__", "line": 89}
{"timestamp": "2025-07-01 15:13:59,998", "level": "INFO", "logger": "root", "message": "\u2705 Progress tracker initialized successfully", "module": "main", "function": "create_api_app", "line": 2440}
{"timestamp": "2025-07-01 15:14:00,000", "level": "INFO", "logger": "root", "message": "FastAPI application created", "module": "main", "function": "create_api_app", "line": 2637}
{"timestamp": "2025-07-01 15:14:00,000", "level": "INFO", "logger": "root", "message": "\u2705 Thread pool captured for cleanup", "module": "main", "function": "main", "line": 145}
{"timestamp": "2025-07-01 15:14:00,001", "level": "INFO", "logger": "root", "message": "FastAPI application created successfully", "module": "main", "function": "main", "line": 149}
{"timestamp": "2025-07-01 15:14:00,001", "level": "INFO", "logger": "root", "message": "Heartbeat monitoring disabled in config", "module": "main", "function": "main", "line": 163}
{"timestamp": "2025-07-01 15:14:00,003", "level": "INFO", "logger": "root", "message": "No folders configured for monitoring", "module": "main", "function": "main", "line": 184}
{"timestamp": "2025-07-01 15:14:00,003", "level": "INFO", "logger": "root", "message": "Starting server on 0.0.0.0:8000", "module": "main", "function": "main", "line": 195}
{"timestamp": "2025-07-01 15:14:00,050", "level": "INFO", "logger": "root", "message": "\ud83d\ude80 RAG System API starting up with managed resources...", "module": "main", "function": "startup_event", "line": 2393}
{"timestamp": "2025-07-01 15:14:00,051", "level": "INFO", "logger": "root", "message": "Registered resource: feedback_store", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:14:00,052", "level": "INFO", "logger": "root", "message": "\ud83d\uded1 RAG System API shutting down - cleaning up managed resources...", "module": "main", "function": "shutdown_event", "line": 2406}
{"timestamp": "2025-07-01 15:14:00,499", "level": "INFO", "logger": "root", "message": "Final system stats: {'app_name': 'GlobalRAGSystem', 'startup_complete': True, 'shutdown_complete': False, 'thread_pools': {'main': {'max_workers': 4, 'shutdown': False}, 'io': {'max_workers': 8, 'shutdown': False}, 'compute': {'max_workers': 2, 'shutdown': False}, 'background': {'max_workers': 2, 'shutdown': False}, 'api_operations': {'max_workers': 8, 'shutdown': False}}, 'resources': {'total_resources': 6, 'resource_names': ['threadpool_main', 'threadpool_io', 'threadpool_compute', 'threadpool_background', 'threadpool_api_operations', 'feedback_store'], 'memory_usage_mb': 521.48828125, 'cpu_percent': 0.0, 'open_files': 3, 'threads': 14}, 'models': {'loaded_models': [], 'total_models': 0, 'memory_usage': {}, 'total_memory_mb': 0.0}, 'timestamp': 1751382840.4993231}", "module": "main", "function": "shutdown_event", "line": 2412}
{"timestamp": "2025-07-01 15:14:00,500", "level": "INFO", "logger": "root", "message": "\u2705 Managed resource cleanup initiated", "module": "main", "function": "shutdown_event", "line": 2416}
{"timestamp": "2025-07-01 15:14:00,514", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Shutting down model memory manager...", "module": "model_memory_manager", "function": "shutdown", "line": 413}
{"timestamp": "2025-07-01 15:14:00,829", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 unloaded. Current memory: 521.51MB", "module": "model_memory_manager", "function": "_unload_model", "line": 260}
{"timestamp": "2025-07-01 15:14:01,173", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Model memory manager shutdown complete", "module": "model_memory_manager", "function": "shutdown", "line": 426}
{"timestamp": "2025-07-01 15:14:01,174", "level": "INFO", "logger": "root", "message": "Shutting down GlobalRAGSystem...", "module": "resource_manager", "function": "shutdown", "line": 423}
{"timestamp": "2025-07-01 15:14:01,587", "level": "INFO", "logger": "root", "message": "Pre-shutdown stats: {'total_resources': 6, 'resource_names': ['threadpool_main', 'threadpool_io', 'threadpool_compute', 'threadpool_background', 'threadpool_api_operations', 'feedback_store'], 'memory_usage_mb': 521.51171875, 'cpu_percent': 0.0, 'open_files': 3, 'threads': 13}", "module": "resource_manager", "function": "shutdown", "line": 428}
{"timestamp": "2025-07-01 15:14:01,589", "level": "INFO", "logger": "root", "message": "Starting comprehensive resource cleanup...", "module": "resource_manager", "function": "cleanup_all", "line": 135}
{"timestamp": "2025-07-01 15:14:01,590", "level": "INFO", "logger": "root", "message": "Custom cleanup completed for feedback_store", "module": "resource_manager", "function": "cleanup_resource", "line": 70}
{"timestamp": "2025-07-01 15:14:01,590", "level": "INFO", "logger": "root", "message": "Cleaned up resource: feedback_store", "module": "resource_manager", "function": "cleanup_resource", "line": 82}
{"timestamp": "2025-07-01 15:14:01,590", "level": "INFO", "logger": "root", "message": "Shutting down thread pool 'api_operations' with 8 workers", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 208}
{"timestamp": "2025-07-01 15:14:01,590", "level": "INFO", "logger": "root", "message": "Thread pool 'api_operations' shutdown completed", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 212}
{"timestamp": "2025-07-01 15:14:01,591", "level": "INFO", "logger": "root", "message": "Custom cleanup completed for threadpool_api_operations", "module": "resource_manager", "function": "cleanup_resource", "line": 70}
{"timestamp": "2025-07-01 15:14:01,591", "level": "INFO", "logger": "root", "message": "Shutting down thread pool: threadpool_api_operations", "module": "resource_manager", "function": "_generic_cleanup", "line": 92}
{"timestamp": "2025-07-01 15:14:01,593", "level": "INFO", "logger": "root", "message": "Cleaned up resource: threadpool_api_operations", "module": "resource_manager", "function": "cleanup_resource", "line": 82}
{"timestamp": "2025-07-01 15:14:01,593", "level": "INFO", "logger": "root", "message": "Shutting down thread pool 'background' with 2 workers", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 208}
{"timestamp": "2025-07-01 15:14:01,593", "level": "INFO", "logger": "root", "message": "Thread pool 'background' shutdown completed", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 212}
{"timestamp": "2025-07-01 15:14:01,594", "level": "INFO", "logger": "root", "message": "Custom cleanup completed for threadpool_background", "module": "resource_manager", "function": "cleanup_resource", "line": 70}
{"timestamp": "2025-07-01 15:14:01,597", "level": "INFO", "logger": "root", "message": "Shutting down thread pool: threadpool_background", "module": "resource_manager", "function": "_generic_cleanup", "line": 92}
{"timestamp": "2025-07-01 15:14:01,598", "level": "INFO", "logger": "root", "message": "Cleaned up resource: threadpool_background", "module": "resource_manager", "function": "cleanup_resource", "line": 82}
{"timestamp": "2025-07-01 15:14:01,598", "level": "INFO", "logger": "root", "message": "Shutting down thread pool 'compute' with 2 workers", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 208}
{"timestamp": "2025-07-01 15:14:01,599", "level": "INFO", "logger": "root", "message": "Thread pool 'compute' shutdown completed", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 212}
{"timestamp": "2025-07-01 15:14:01,599", "level": "INFO", "logger": "root", "message": "Custom cleanup completed for threadpool_compute", "module": "resource_manager", "function": "cleanup_resource", "line": 70}
{"timestamp": "2025-07-01 15:14:01,600", "level": "INFO", "logger": "root", "message": "Shutting down thread pool: threadpool_compute", "module": "resource_manager", "function": "_generic_cleanup", "line": 92}
{"timestamp": "2025-07-01 15:14:01,606", "level": "INFO", "logger": "root", "message": "Cleaned up resource: threadpool_compute", "module": "resource_manager", "function": "cleanup_resource", "line": 82}
{"timestamp": "2025-07-01 15:14:01,606", "level": "INFO", "logger": "root", "message": "Shutting down thread pool 'io' with 8 workers", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 208}
{"timestamp": "2025-07-01 15:14:01,608", "level": "INFO", "logger": "root", "message": "Thread pool 'io' shutdown completed", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 212}
{"timestamp": "2025-07-01 15:14:01,608", "level": "INFO", "logger": "root", "message": "Custom cleanup completed for threadpool_io", "module": "resource_manager", "function": "cleanup_resource", "line": 70}
{"timestamp": "2025-07-01 15:14:01,615", "level": "INFO", "logger": "root", "message": "Shutting down thread pool: threadpool_io", "module": "resource_manager", "function": "_generic_cleanup", "line": 92}
{"timestamp": "2025-07-01 15:14:01,616", "level": "INFO", "logger": "root", "message": "Cleaned up resource: threadpool_io", "module": "resource_manager", "function": "cleanup_resource", "line": 82}
{"timestamp": "2025-07-01 15:14:01,616", "level": "INFO", "logger": "root", "message": "Shutting down thread pool 'main' with 4 workers", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 208}
{"timestamp": "2025-07-01 15:14:01,617", "level": "INFO", "logger": "root", "message": "Thread pool 'main' shutdown completed", "module": "resource_manager", "function": "cleanup_with_timeout", "line": 212}
{"timestamp": "2025-07-01 15:14:01,617", "level": "INFO", "logger": "root", "message": "Custom cleanup completed for threadpool_main", "module": "resource_manager", "function": "cleanup_resource", "line": 70}
{"timestamp": "2025-07-01 15:14:01,618", "level": "INFO", "logger": "root", "message": "Shutting down thread pool: threadpool_main", "module": "resource_manager", "function": "_generic_cleanup", "line": 92}
{"timestamp": "2025-07-01 15:14:01,618", "level": "INFO", "logger": "root", "message": "Cleaned up resource: threadpool_main", "module": "resource_manager", "function": "cleanup_resource", "line": 82}
{"timestamp": "2025-07-01 15:14:01,993", "level": "INFO", "logger": "root", "message": "Resource cleanup completed", "module": "resource_manager", "function": "cleanup_all", "line": 150}
{"timestamp": "2025-07-01 15:14:02,311", "level": "INFO", "logger": "root", "message": "GlobalRAGSystem shutdown completed", "module": "resource_manager", "function": "shutdown", "line": 440}
{"timestamp": "2025-07-01 15:14:02,315", "level": "INFO", "logger": "root", "message": "\u2705 API thread pool shutdown complete", "module": "main", "function": "cleanup_thread_pool", "line": 25}
{"timestamp": "2025-07-01 15:14:02,315", "level": "INFO", "logger": "root", "message": "\ud83d\udd04 Cleaning up global application lifecycle...", "module": "main", "function": "cleanup_thread_pool", "line": 36}
{"timestamp": "2025-07-01 15:14:02,316", "level": "INFO", "logger": "root", "message": "\u2705 Global application lifecycle cleanup complete", "module": "main", "function": "cleanup_thread_pool", "line": 38}
{"timestamp": "2025-07-01 15:14:02,316", "level": "INFO", "logger": "root", "message": "\u2705 All resource manager instances cleaned up", "module": "main", "function": "cleanup_thread_pool", "line": 42}
{"timestamp": "2025-07-01 15:22:18,510", "level": "INFO", "logger": "root", "message": "RAG System initialization started", "module": "system_init", "function": "initialize_system", "line": 222}
{"timestamp": "2025-07-01 15:22:18,514", "level": "INFO", "logger": "root", "message": "Created data directories: ['data', 'data/metadata', 'data/metadata/config', 'data/vectors', 'data/uploads', 'data/logs', 'data/backups', 'logs']", "module": "system_init", "function": "create_data_directories", "line": 102}
{"timestamp": "2025-07-01 15:22:18,515", "level": "INFO", "logger": "root", "message": "Validating system requirements...", "module": "system_init", "function": "validate_system_requirements", "line": 108}
{"timestamp": "2025-07-01 15:22:18,516", "level": "INFO", "logger": "root", "message": "System requirements validation completed", "module": "system_init", "function": "validate_system_requirements", "line": 152}
{"timestamp": "2025-07-01 15:22:18,543", "level": "INFO", "logger": "root", "message": "Error tracking initialized", "module": "system_init", "function": "initialize_error_tracking", "line": 169}
{"timestamp": "2025-07-01 15:22:18,543", "level": "INFO", "logger": "root", "message": "Initializing core components...", "module": "system_init", "function": "initialize_system", "line": 241}
{"timestamp": "2025-07-01 15:22:20,327", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:20,342", "level": "INFO", "logger": "httpx", "message": "HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:20,344", "level": "INFO", "logger": "root", "message": "Using existing collection: rag_documents", "module": "qdrant_store", "function": "_init_collection", "line": 84}
{"timestamp": "2025-07-01 15:22:20,346", "level": "INFO", "logger": "root", "message": "Qdrant store initialized: localhost:6333/rag_documents", "module": "qdrant_store", "function": "__init__", "line": 67}
{"timestamp": "2025-07-01 15:22:20,915", "level": "INFO", "logger": "root", "message": "Loaded Azure AI Inference client with model: Cohere-embed-v3-english", "module": "embedder", "function": "_load_client", "line": 178}
{"timestamp": "2025-07-01 15:22:20,916", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '81'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '2e8383d0-568f-11f0-b177-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 15:22:21,041", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 15:22:20 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 15:22:21,047", "level": "INFO", "logger": "root", "message": "Azure embedding dimension: 1024", "module": "embedder", "function": "_load_client", "line": 187}
{"timestamp": "2025-07-01 15:22:21,047", "level": "INFO", "logger": "root", "message": "Embedder initialized with provider: azure", "module": "embedder", "function": "__init__", "line": 243}
{"timestamp": "2025-07-01 15:22:21,473", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq (timeout: 30s)", "module": "llm_client", "function": "__init__", "line": 196}
{"timestamp": "2025-07-01 15:22:21,474", "level": "INFO", "logger": "root", "message": "LLM client initialized: groq", "module": "system_init", "function": "initialize_system", "line": 270}
{"timestamp": "2025-07-01 15:22:21,477", "level": "INFO", "logger": "root", "message": "\u2705 RAG System initialization completed successfully", "module": "system_init", "function": "initialize_system", "line": 282}
{"timestamp": "2025-07-01 15:22:21,478", "level": "INFO", "logger": "root", "message": "System Configuration: {'environment': 'development', 'debug_mode': True, 'data_directory': 'data', 'embedding_model': 'Cohere-embed-v3-english', 'llm_provider': 'groq', 'llm_model': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'api_host': '0.0.0.0', 'api_port': 8000, 'registered_services': ['servicenow_integration', 'embedder', 'json_store', 'config_manager', 'verified_ingestion_engine', 'chunker', 'ingestion_engine', 'llm_client', 'ingestion_verifier', 'vector_store', 'reranker', 'query_enhancer', 'query_engine', 'log_store', 'metadata_store', 'conversation_manager', 'ingestion_debugger', 'faiss_store']}", "module": "system_init", "function": "log_system_info", "line": 319}
{"timestamp": "2025-07-01 15:22:21,482", "level": "INFO", "logger": "root", "message": "Setting up monitoring...", "module": "main", "function": "main", "line": 77}
{"timestamp": "2025-07-01 15:22:21,482", "level": "INFO", "logger": "root", "message": "Monitoring setup completed", "module": "setup", "function": "setup_monitoring", "line": 18}
{"timestamp": "2025-07-01 15:22:21,483", "level": "INFO", "logger": "root", "message": "Initializing heartbeat monitor...", "module": "main", "function": "main", "line": 87}
{"timestamp": "2025-07-01 15:22:21,483", "level": "INFO", "logger": "src.monitoring.heartbeat_monitor", "message": "Heartbeat monitor initialized", "module": "heartbeat_monitor", "function": "__init__", "line": 85}
{"timestamp": "2025-07-01 15:22:21,484", "level": "INFO", "logger": "root", "message": "\u2705 Heartbeat monitor initialized successfully", "module": "main", "function": "main", "line": 89}
{"timestamp": "2025-07-01 15:22:21,486", "level": "INFO", "logger": "root", "message": "Initializing folder monitor...", "module": "main", "function": "main", "line": 98}
{"timestamp": "2025-07-01 15:22:21,486", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Loaded folder monitoring config: 0 folders, 60s interval", "module": "folder_monitor", "function": "_load_config", "line": 95}
{"timestamp": "2025-07-01 15:22:21,495", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Folder monitor initialized", "module": "folder_monitor", "function": "__init__", "line": 76}
{"timestamp": "2025-07-01 15:22:21,496", "level": "INFO", "logger": "root", "message": "\u2705 Folder monitor initialized successfully", "module": "main", "function": "main", "line": 101}
{"timestamp": "2025-07-01 15:22:21,949", "level": "INFO", "logger": "root", "message": "Initializing enhanced folder monitor...", "module": "main", "function": "main", "line": 110}
{"timestamp": "2025-07-01 15:22:21,950", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Loaded folder monitoring config: 0 folders, 60s interval", "module": "folder_monitor", "function": "_load_config", "line": 95}
{"timestamp": "2025-07-01 15:22:21,950", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Folder monitor initialized", "module": "folder_monitor", "function": "__init__", "line": 76}
{"timestamp": "2025-07-01 15:22:21,950", "level": "INFO", "logger": "src.monitoring.folder_monitor", "message": "Enhanced folder monitor initialized with pipeline verification", "module": "enhanced_folder_monitor", "function": "__init__", "line": 84}
{"timestamp": "2025-07-01 15:22:21,951", "level": "INFO", "logger": "root", "message": "\u2705 Enhanced folder monitor initialized successfully", "module": "main", "function": "main", "line": 113}
{"timestamp": "2025-07-01 15:22:22,004", "level": "INFO", "logger": "root", "message": "\u2705 Heartbeat monitor registered with API", "module": "main", "function": "main", "line": 122}
{"timestamp": "2025-07-01 15:22:22,005", "level": "INFO", "logger": "root", "message": "\u2705 Folder monitor registered with API", "module": "main", "function": "main", "line": 130}
{"timestamp": "2025-07-01 15:22:22,005", "level": "INFO", "logger": "root", "message": "Creating FastAPI application...", "module": "main", "function": "main", "line": 136}
{"timestamp": "2025-07-01 15:22:22,006", "level": "INFO", "logger": "root", "message": "ResourceManager initialized", "module": "resource_manager", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 15:22:22,006", "level": "INFO", "logger": "root", "message": "Initialized GlobalRAGSystem lifecycle manager", "module": "resource_manager", "function": "__init__", "line": 390}
{"timestamp": "2025-07-01 15:22:22,006", "level": "INFO", "logger": "root", "message": "Starting GlobalRAGSystem...", "module": "resource_manager", "function": "startup", "line": 398}
{"timestamp": "2025-07-01 15:22:22,007", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_main", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:22:22,007", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'main' with 4 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:22:22,007", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_io", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:22:22,008", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'io' with 8 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:22:22,012", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_compute", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:22:22,015", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'compute' with 2 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:22:22,016", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_background", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:22:22,017", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'background' with 2 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:22:22,028", "level": "INFO", "logger": "root", "message": "GlobalRAGSystem startup completed successfully", "module": "resource_manager", "function": "startup", "line": 411}
{"timestamp": "2025-07-01 15:22:22,032", "level": "INFO", "logger": "root", "message": "Registered resource: threadpool_api_operations", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:22:22,033", "level": "INFO", "logger": "root", "message": "Created managed thread pool 'api_operations' with 8 workers", "module": "resource_manager", "function": "__init__", "line": 229}
{"timestamp": "2025-07-01 15:22:22,033", "level": "INFO", "logger": "root", "message": "\u2705 Heartbeat monitor set in API: <class 'src.monitoring.heartbeat_monitor.HeartbeatMonitor'>", "module": "main", "function": "create_api_app", "line": 227}
{"timestamp": "2025-07-01 15:22:22,034", "level": "INFO", "logger": "root", "message": "\u2705 Folder monitor set in API: <class 'src.monitoring.folder_monitor.FolderMonitor'>", "module": "main", "function": "create_api_app", "line": 240}
{"timestamp": "2025-07-01 15:22:22,036", "level": "INFO", "logger": "src.storage.feedback_store", "message": "Feedback store initialized at: data\\feedback_store.db", "module": "feedback_store", "function": "__init__", "line": 29}
{"timestamp": "2025-07-01 15:22:22,071", "level": "INFO", "logger": "root", "message": "\u2705 Management API routes registered", "module": "main", "function": "create_api_app", "line": 2341}
{"timestamp": "2025-07-01 15:22:22,087", "level": "WARNING", "logger": "root", "message": "\u26a0\ufe0f ServiceNow API routes not available: No module named 'rag_system'", "module": "main", "function": "create_api_app", "line": 2356}
{"timestamp": "2025-07-01 15:22:22,099", "level": "INFO", "logger": "root", "message": "\u2705 Conversation API routes registered", "module": "main", "function": "create_api_app", "line": 2365}
{"timestamp": "2025-07-01 15:22:22,109", "level": "INFO", "logger": "root", "message": "\u2705 Verification API routes registered", "module": "main", "function": "create_api_app", "line": 2373}
{"timestamp": "2025-07-01 15:22:22,141", "level": "INFO", "logger": "root", "message": "\u2705 Enhanced folder monitoring API routes registered", "module": "main", "function": "create_api_app", "line": 2383}
{"timestamp": "2025-07-01 15:22:22,163", "level": "INFO", "logger": "root", "message": "Progress tracker initialized", "module": "progress_tracker", "function": "__init__", "line": 172}
{"timestamp": "2025-07-01 15:22:22,518", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Model memory manager initialized - Max memory: 2048MB, Idle timeout: 300s", "module": "model_memory_manager", "function": "__init__", "line": 95}
{"timestamp": "2025-07-01 15:22:22,527", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Loading model: semantic_chunker_all-MiniLM-L6-v2", "module": "model_memory_manager", "function": "get_model", "line": 117}
{"timestamp": "2025-07-01 15:22:22,528", "level": "INFO", "logger": "root", "message": "Loading sentence transformer: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "load_model", "line": 340}
{"timestamp": "2025-07-01 15:22:22,530", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Use pytorch device_name: cpu", "module": "SentenceTransformer", "function": "__init__", "line": 211}
{"timestamp": "2025-07-01 15:22:22,531", "level": "INFO", "logger": "sentence_transformers.SentenceTransformer", "message": "Load pretrained SentenceTransformer: all-MiniLM-L6-v2", "module": "SentenceTransformer", "function": "__init__", "line": 219}
{"timestamp": "2025-07-01 15:22:25,896", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 loaded in 3.37s. Current memory: 520.27MB", "module": "model_memory_manager", "function": "get_model", "line": 144}
{"timestamp": "2025-07-01 15:22:25,904", "level": "INFO", "logger": "root", "message": "Semantic chunker initialized with memory-managed model: all-MiniLM-L6-v2", "module": "semantic_chunker", "function": "_initialize_model", "line": 345}
{"timestamp": "2025-07-01 15:22:25,904", "level": "INFO", "logger": "root", "message": "Chunker initialized with semantic chunking (model loads on demand): size=1000, overlap=200", "module": "chunker", "function": "__init__", "line": 47}
{"timestamp": "2025-07-01 15:22:25,907", "level": "INFO", "logger": "root", "message": "Progress tracker initialized", "module": "progress_tracker", "function": "__init__", "line": 172}
{"timestamp": "2025-07-01 15:22:25,907", "level": "INFO", "logger": "root", "message": "DEBUG: Created processor config with keys: ['chunk_size', 'chunk_overlap', 'supported_formats', 'max_file_size_mb', 'batch_size', 'timeout', 'file_timeout']", "module": "ingestion_engine", "function": "__init__", "line": 45}
{"timestamp": "2025-07-01 15:22:25,908", "level": "INFO", "logger": "root", "message": "Azure AI config added to processor config", "module": "ingestion_engine", "function": "__init__", "line": 54}
{"timestamp": "2025-07-01 15:22:25,908", "level": "INFO", "logger": "ExcelProcessor", "message": "Excel processor initialized with Azure AI support", "module": "excel_processor", "function": "__init__", "line": 85}
{"timestamp": "2025-07-01 15:22:25,908", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ExcelProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:22:25,909", "level": "INFO", "logger": "root", "message": "Extracted Azure AI config from general config", "module": "pdf_processor", "function": "create_pdf_processor", "line": 82}
{"timestamp": "2025-07-01 15:22:26,343", "level": "INFO", "logger": "src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 15:22:26,344", "level": "INFO", "logger": "root", "message": "Azure AI client created successfully for PDF processing", "module": "pdf_processor", "function": "create_pdf_processor", "line": 93}
{"timestamp": "2025-07-01 15:22:26,344", "level": "INFO", "logger": "root", "message": "Azure CV endpoint: https://computervision1298.cognitiveservices.azure...", "module": "pdf_processor", "function": "create_pdf_processor", "line": 94}
{"timestamp": "2025-07-01 15:22:26,344", "level": "INFO", "logger": "root", "message": "Using EnhancedPDFProcessor with Azure AI integration", "module": "pdf_processor", "function": "create_pdf_processor", "line": 106}
{"timestamp": "2025-07-01 15:22:26,345", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:22:26,345", "level": "INFO", "logger": "WordProcessor", "message": "Word processor initialized", "module": "word_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 15:22:26,345", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: WordProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:22:26,345", "level": "INFO", "logger": "ImageProcessor", "message": "Image processor initialized", "module": "image_processor", "function": "__init__", "line": 26}
{"timestamp": "2025-07-01 15:22:26,346", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ImageProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:22:26,346", "level": "INFO", "logger": "ServiceNowProcessor", "message": "ServiceNow processor initialized", "module": "servicenow_processor", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 15:22:26,347", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: ServiceNowProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:22:26,348", "level": "INFO", "logger": "TextProcessor", "message": "Text processor initialized", "module": "text_processor", "function": "__init__", "line": 30}
{"timestamp": "2025-07-01 15:22:26,348", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: TextProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:22:26,351", "level": "INFO", "logger": "src.integrations.azure_ai.azure_client", "message": "Azure Computer Vision client initialized successfully", "module": "azure_client", "function": "_initialize_clients", "line": 78}
{"timestamp": "2025-07-01 15:22:26,351", "level": "INFO", "logger": "src.ingestion.processors.base_processor", "message": "Registered processor: EnhancedPDFProcessor", "module": "base_processor", "function": "register", "line": 90}
{"timestamp": "2025-07-01 15:22:26,352", "level": "INFO", "logger": "root", "message": "Enhanced PDF Processor with Azure CV registered successfully", "module": "ingestion_engine", "function": "__init__", "line": 73}
{"timestamp": "2025-07-01 15:22:26,352", "level": "INFO", "logger": "root", "message": "Processor registry initialized with 7 processors", "module": "ingestion_engine", "function": "__init__", "line": 77}
{"timestamp": "2025-07-01 15:22:26,353", "level": "INFO", "logger": "root", "message": "Ingestion engine initialized with managed metadata", "module": "ingestion_engine", "function": "__init__", "line": 89}
{"timestamp": "2025-07-01 15:22:26,353", "level": "INFO", "logger": "root", "message": "\u2705 Progress tracker initialized successfully", "module": "main", "function": "create_api_app", "line": 2440}
{"timestamp": "2025-07-01 15:22:26,355", "level": "INFO", "logger": "root", "message": "FastAPI application created", "module": "main", "function": "create_api_app", "line": 2637}
{"timestamp": "2025-07-01 15:22:26,355", "level": "INFO", "logger": "root", "message": "\u2705 Thread pool captured for cleanup", "module": "main", "function": "main", "line": 145}
{"timestamp": "2025-07-01 15:22:26,356", "level": "INFO", "logger": "root", "message": "FastAPI application created successfully", "module": "main", "function": "main", "line": 149}
{"timestamp": "2025-07-01 15:22:26,356", "level": "INFO", "logger": "root", "message": "Heartbeat monitoring disabled in config", "module": "main", "function": "main", "line": 163}
{"timestamp": "2025-07-01 15:22:26,357", "level": "INFO", "logger": "root", "message": "No folders configured for monitoring", "module": "main", "function": "main", "line": 184}
{"timestamp": "2025-07-01 15:22:26,357", "level": "INFO", "logger": "root", "message": "Starting server on 0.0.0.0:8000", "module": "main", "function": "main", "line": 195}
{"timestamp": "2025-07-01 15:22:26,418", "level": "INFO", "logger": "root", "message": "\ud83d\ude80 RAG System API starting up with managed resources...", "module": "main", "function": "startup_event", "line": 2393}
{"timestamp": "2025-07-01 15:22:26,419", "level": "INFO", "logger": "root", "message": "Registered resource: feedback_store", "module": "resource_manager", "function": "register_resource", "line": 50}
{"timestamp": "2025-07-01 15:22:45,795", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Initialized Memory checkpointer for state persistence", "module": "conversation_graph", "function": "__init__", "line": 36}
{"timestamp": "2025-07-01 15:22:45,912", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation graph compiled successfully with Memory state persistence", "module": "conversation_graph", "function": "_build_graph", "line": 104}
{"timestamp": "2025-07-01 15:22:46,017", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "ConversationGraph initialized with state persistence", "module": "conversation_graph", "function": "__init__", "line": 41}
{"timestamp": "2025-07-01 15:22:46,132", "level": "WARNING", "logger": "src.conversation.conversation_graph", "message": "Checkpointer not available or missing client attribute", "module": "conversation_graph", "function": "list_conversation_threads", "line": 309}
{"timestamp": "2025-07-01 15:22:46,203", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Conversation cleanup completed: 0 old conversations removed", "module": "conversation_manager", "function": "cleanup_old_conversations", "line": 173}
{"timestamp": "2025-07-01 15:22:46,252", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Initial conversation cleanup: 0 conversations removed", "module": "conversation_manager", "function": "__init__", "line": 34}
{"timestamp": "2025-07-01 15:22:46,261", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "ConversationManager initialized with LangGraph state persistence and memory management", "module": "conversation_manager", "function": "__init__", "line": 38}
{"timestamp": "2025-07-01 15:22:46,293", "level": "INFO", "logger": "src.api.routes.conversation", "message": "ConversationManager initialized from container", "module": "conversation", "function": "get_conversation_manager", "line": 68}
{"timestamp": "2025-07-01 15:22:46,372", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Created new conversation state for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_graph", "function": "_get_or_create_state", "line": 259}
{"timestamp": "2025-07-01 15:22:46,549", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:22:46,669", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:22:46,671", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: None, turn: 1", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:22:46,672", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:22:46,821", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:22:46,822", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:22:46,822", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated without search results", "module": "conversation_nodes", "function": "generate_response", "line": 354}
{"timestamp": "2025-07-01 15:22:46,823", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:22:46,823", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=None, turns=2", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:22:46,825", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 36822106-bd3a-4710-a661-5463c08cbf40, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:22:46,825", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Started/retrieved conversation for thread: 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_manager", "function": "start_conversation", "line": 53}
{"timestamp": "2025-07-01 15:22:48,864", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 15:22:48,889", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:22:48,890", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:22:48,891", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Conversation has history - treating with partial context", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 424}
{"timestamp": "2025-07-01 15:22:48,891", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Building contextual query from: 'How many tickets in the system'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 15:22:48,891", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Enhanced query to: 'How many tickets in the system (context: )'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 15:22:48,892", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'How many tickets in the system (context: )'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 15:22:48,893", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['many', 'tickets', 'system']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 15:22:48,904", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 15:22:48,904", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 15:22:48,905", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 3", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:22:48,984", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:22:48,985", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 15:22:48,986", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'How many tickets in the system (context: )'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 15:22:48,986", "level": "INFO", "logger": "root", "message": "Query type detected: aggregation", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:22:49,039", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,070", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,199", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,227", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,355", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,356", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 2: Original query: 'How many tickets in the system'", "module": "conversation_nodes", "function": "search_knowledge", "line": 182}
{"timestamp": "2025-07-01 15:22:49,357", "level": "INFO", "logger": "root", "message": "Query type detected: aggregation", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:22:49,437", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,540", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,578", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,673", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,923", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:49,944", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 15:22:49,945", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'aggregation_results', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 15:22:49,945", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "No sources found in search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 262}
{"timestamp": "2025-07-01 15:22:49,947", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:22:49,948", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:22:49,948", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83d\ude80 Generating follow-up questions", "module": "conversation_nodes", "function": "generate_response", "line": 337}
{"timestamp": "2025-07-01 15:22:49,949", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83d\udd25 FOLLOW-UP QUESTIONS METHOD CALLED \ud83d\udd25", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 791}
{"timestamp": "2025-07-01 15:22:49,949", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Starting follow-up question generation", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 807}
{"timestamp": "2025-07-01 15:22:49,950", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Built context info with length: 326", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 816}
{"timestamp": "2025-07-01 15:22:49,950", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Sending prompt to LLM for follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 842}
{"timestamp": "2025-07-01 15:22:50,410", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:50,422", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "LLM response length: 542", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 844}
{"timestamp": "2025-07-01 15:22:50,423", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Parsed 4 questions from LLM response", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 848}
{"timestamp": "2025-07-01 15:22:50,423", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Generated 4 contextual follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 851}
{"timestamp": "2025-07-01 15:22:50,439", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf Generated 4 suggested questions", "module": "conversation_nodes", "function": "generate_response", "line": 339}
{"timestamp": "2025-07-01 15:22:50,439", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated without search results", "module": "conversation_nodes", "function": "generate_response", "line": 354}
{"timestamp": "2025-07-01 15:22:50,440", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:22:50,440", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=4", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:22:50,596", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 36822106-bd3a-4710-a661-5463c08cbf40, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:22:50,640", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Processed message for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_manager", "function": "process_user_message", "line": 74}
{"timestamp": "2025-07-01 15:22:54,858", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 15:22:54,986", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:22:55,008", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:22:55,008", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual pattern matched: (that|this|those|these|it|them)", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 414}
{"timestamp": "2025-07-01 15:22:55,009", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Building contextual query from: 'which are these?'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 15:22:55,009", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Enhanced query to: 'which are these? (context: )'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 15:22:55,010", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'which are these? (context: )'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 15:22:55,010", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['which', 'these']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 15:22:55,010", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 15:22:55,011", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 15:22:55,012", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 5", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:22:55,194", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:22:55,199", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 15:22:55,199", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'which are these? (context: )'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 15:22:55,200", "level": "INFO", "logger": "root", "message": "Query type detected: semantic_search", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:22:55,217", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '105'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '42f54e81-568f-11f0-b930-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 15:22:55,271", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 15:22:54 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 15:22:55,353", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/search \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:56,245", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:56,247", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 15:22:56,247", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'sources', 'total_sources', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 15:22:56,248", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing 5 sources from search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 235}
{"timestamp": "2025-07-01 15:22:56,248", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Found 5 relevant sources", "module": "conversation_nodes", "function": "search_knowledge", "line": 259}
{"timestamp": "2025-07-01 15:22:56,249", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:22:56,250", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:22:56,250", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Generating contextual response with 5 search results", "module": "conversation_nodes", "function": "_generate_contextual_response", "line": 559}
{"timestamp": "2025-07-01 15:22:56,433", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:57,539", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:22:57,561", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated using sources: ['unknown', 'unknown', 'unknown']", "module": "conversation_nodes", "function": "generate_response", "line": 352}
{"timestamp": "2025-07-01 15:22:57,562", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:22:57,562", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=6", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:22:57,632", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 36822106-bd3a-4710-a661-5463c08cbf40, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:22:57,637", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Processed message for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_manager", "function": "process_user_message", "line": 74}
{"timestamp": "2025-07-01 15:23:02,699", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 15:23:05,726", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:23:05,734", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:23:05,735", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Conversation has history - treating with partial context", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 424}
{"timestamp": "2025-07-01 15:23:05,735", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Building contextual query from: 'We have 3 access points in Building A'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 15:23:05,736", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Enhanced query to: 'We have 3 access points in Building A (context: access points Building A)'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 15:23:05,737", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'We have 3 access points in Building A (context: access points Building A)'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 15:23:05,766", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['access', 'points', 'building']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 15:23:05,767", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 15:23:05,767", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 15:23:05,767", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 7", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:23:05,884", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:23:05,889", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 15:23:05,889", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'We have 3 access points in Building A (context: access points Building A)'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 15:23:05,890", "level": "INFO", "logger": "root", "message": "Query type detected: semantic_search", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:23:05,898", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '150'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '495327b8-568f-11f0-82a9-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 15:23:06,013", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 15:23:05 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 15:23:06,049", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/search \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:06,623", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:06,696", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 15:23:06,696", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'sources', 'total_sources', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 15:23:06,697", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing 5 sources from search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 235}
{"timestamp": "2025-07-01 15:23:06,698", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Found 5 relevant sources", "module": "conversation_nodes", "function": "search_knowledge", "line": 259}
{"timestamp": "2025-07-01 15:23:06,700", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:23:06,701", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:23:06,702", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Generating contextual response with 5 search results", "module": "conversation_nodes", "function": "_generate_contextual_response", "line": 559}
{"timestamp": "2025-07-01 15:23:07,165", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:08,230", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:08,233", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated using sources: ['unknown', 'unknown', 'unknown']", "module": "conversation_nodes", "function": "generate_response", "line": 352}
{"timestamp": "2025-07-01 15:23:08,235", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:23:08,235", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=8", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:23:08,294", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 36822106-bd3a-4710-a661-5463c08cbf40, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:23:08,295", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Processed message for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_manager", "function": "process_user_message", "line": 74}
{"timestamp": "2025-07-01 15:23:12,353", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 15:23:12,360", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:23:12,362", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:23:12,372", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual pattern matched: (that|this|those|these|it|them)", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 414}
{"timestamp": "2025-07-01 15:23:12,372", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Building contextual query from: 'what are those?'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 15:23:12,373", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Enhanced query to: 'what are those? access points Building A'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 15:23:12,373", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'what are those? access points Building A'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 15:23:12,374", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['those']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 15:23:12,374", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 15:23:12,374", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 15:23:12,375", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 9", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:23:12,381", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:23:12,387", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 15:23:12,388", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'what are those? access points Building A'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 15:23:12,388", "level": "INFO", "logger": "root", "message": "Query type detected: semantic_search", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:23:12,403", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '117'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '4d33c1ed-568f-11f0-80dd-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 15:23:12,529", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 15:23:11 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 15:23:12,546", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/search \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:13,498", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:13,503", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 15:23:13,504", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'sources', 'total_sources', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 15:23:13,504", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing 5 sources from search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 235}
{"timestamp": "2025-07-01 15:23:13,504", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Found 5 relevant sources", "module": "conversation_nodes", "function": "search_knowledge", "line": 259}
{"timestamp": "2025-07-01 15:23:13,505", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:23:13,506", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:23:13,506", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Generating contextual response with 5 search results", "module": "conversation_nodes", "function": "_generate_contextual_response", "line": 559}
{"timestamp": "2025-07-01 15:23:13,691", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:14,775", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:14,778", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83d\ude80 Generating follow-up questions", "module": "conversation_nodes", "function": "generate_response", "line": 337}
{"timestamp": "2025-07-01 15:23:14,780", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83d\udd25 FOLLOW-UP QUESTIONS METHOD CALLED \ud83d\udd25", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 791}
{"timestamp": "2025-07-01 15:23:14,780", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Starting follow-up question generation", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 807}
{"timestamp": "2025-07-01 15:23:14,780", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Built context info with length: 1342", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 816}
{"timestamp": "2025-07-01 15:23:14,780", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Sending prompt to LLM for follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 842}
{"timestamp": "2025-07-01 15:23:15,905", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:15,910", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "LLM response length: 416", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 844}
{"timestamp": "2025-07-01 15:23:15,911", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Parsed 3 questions from LLM response", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 848}
{"timestamp": "2025-07-01 15:23:15,911", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Generated 3 contextual follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 851}
{"timestamp": "2025-07-01 15:23:15,911", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf Generated 3 suggested questions", "module": "conversation_nodes", "function": "generate_response", "line": 339}
{"timestamp": "2025-07-01 15:23:15,912", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated using sources: ['unknown', 'unknown', 'unknown']", "module": "conversation_nodes", "function": "generate_response", "line": 352}
{"timestamp": "2025-07-01 15:23:15,912", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:23:15,912", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=10", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:23:15,978", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 36822106-bd3a-4710-a661-5463c08cbf40, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:23:15,979", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Processed message for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_manager", "function": "process_user_message", "line": 74}
{"timestamp": "2025-07-01 15:23:21,036", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 15:23:21,100", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:23:21,109", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:23:21,110", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual pattern matched: (that|this|those|these|it|them)", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 414}
{"timestamp": "2025-07-01 15:23:21,110", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Building contextual query from: 'There are 5 network incidents this week'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 15:23:21,111", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Enhanced query to: 'There are 5 network incidents this week (context: )'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 15:23:21,111", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'There are 5 network incidents this week (context: )'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 15:23:21,111", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['there', 'network', 'incidents', 'this', 'week']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 15:23:21,112", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 15:23:21,112", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 15:23:21,122", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 11", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:23:21,135", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:23:21,136", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 15:23:21,137", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'There are 5 network incidents this week (context: )'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 15:23:21,137", "level": "INFO", "logger": "root", "message": "Query type detected: semantic_search", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:23:21,143", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '128'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '52695ea4-568f-11f0-a877-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 15:23:21,353", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 15:23:20 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 15:23:21,413", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/search \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:21,498", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:21,506", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.386296 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:21,969", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:21,973", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.975405 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:23,007", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:24,580", "level": "ERROR", "logger": "root", "message": "Groq generation error: no healthy upstream", "module": "llm_client", "function": "generate", "line": 91}
{"timestamp": "2025-07-01 15:23:24,580", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "llm_client", "function": "generate", "line": 249}
{"timestamp": "2025-07-01 15:23:24,581", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "qdrant_query_engine", "function": "_generate_llm_response", "line": 339}
{"timestamp": "2025-07-01 15:23:24,581", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 15:23:24,591", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'sources', 'total_sources', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 15:23:24,592", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing 5 sources from search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 235}
{"timestamp": "2025-07-01 15:23:24,592", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Found 5 relevant sources", "module": "conversation_nodes", "function": "search_knowledge", "line": 259}
{"timestamp": "2025-07-01 15:23:24,593", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:23:24,594", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:23:24,594", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Generating contextual response with 5 search results", "module": "conversation_nodes", "function": "_generate_contextual_response", "line": 559}
{"timestamp": "2025-07-01 15:23:24,657", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:25,124", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.460845 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:25,668", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:25,670", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.851413 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:26,586", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:26,603", "level": "ERROR", "logger": "root", "message": "Groq generation error: no healthy upstream", "module": "llm_client", "function": "generate", "line": 91}
{"timestamp": "2025-07-01 15:23:26,603", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "llm_client", "function": "generate", "line": 249}
{"timestamp": "2025-07-01 15:23:26,604", "level": "ERROR", "logger": "src.conversation.conversation_nodes", "message": "LLM intent detection failed: Groq generation failed: no healthy upstream", "module": "conversation_nodes", "function": "_is_simple_followup_question", "line": 537}
{"timestamp": "2025-07-01 15:23:26,659", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:26,672", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.438110 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:27,173", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:27,174", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.809703 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:28,044", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:28,133", "level": "ERROR", "logger": "root", "message": "Groq generation error: no healthy upstream", "module": "llm_client", "function": "generate", "line": 91}
{"timestamp": "2025-07-01 15:23:28,133", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "llm_client", "function": "generate", "line": 249}
{"timestamp": "2025-07-01 15:23:28,133", "level": "ERROR", "logger": "src.conversation.conversation_nodes", "message": "LLM intent detection failed: Groq generation failed: no healthy upstream", "module": "conversation_nodes", "function": "_is_simple_followup_question", "line": 537}
{"timestamp": "2025-07-01 15:23:28,134", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated using sources: ['unknown', 'unknown', 'unknown']", "module": "conversation_nodes", "function": "generate_response", "line": 352}
{"timestamp": "2025-07-01 15:23:28,134", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:23:28,135", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=12", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:23:28,283", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 36822106-bd3a-4710-a661-5463c08cbf40, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:23:28,403", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Processed message for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_manager", "function": "process_user_message", "line": 74}
{"timestamp": "2025-07-01 15:23:32,516", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 15:23:32,541", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:23:32,541", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:23:32,543", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual pattern matched: ^(list|show|give me)", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 414}
{"timestamp": "2025-07-01 15:23:32,543", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Building contextual query from: 'show them'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 15:23:32,543", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Enhanced query to: 'show them (context: )'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 15:23:32,543", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'show them (context: )'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 15:23:32,544", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['show', 'them']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 15:23:32,544", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 15:23:32,544", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 15:23:32,545", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 13", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:23:32,549", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:23:32,549", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 15:23:32,551", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'show them (context: )'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 15:23:32,551", "level": "INFO", "logger": "root", "message": "Query type detected: semantic_search", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:23:32,558", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '98'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '593718d6-568f-11f0-a9b3-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 15:23:32,630", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 15:23:31 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 15:23:32,643", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/search \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:32,705", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:32,706", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.424063 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:33,194", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:33,194", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.792215 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:34,048", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:34,061", "level": "ERROR", "logger": "root", "message": "Groq generation error: no healthy upstream", "module": "llm_client", "function": "generate", "line": 91}
{"timestamp": "2025-07-01 15:23:34,061", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "llm_client", "function": "generate", "line": 249}
{"timestamp": "2025-07-01 15:23:34,062", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "qdrant_query_engine", "function": "_generate_llm_response", "line": 339}
{"timestamp": "2025-07-01 15:23:34,062", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 15:23:34,062", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'sources', 'total_sources', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 15:23:34,062", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing 5 sources from search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 235}
{"timestamp": "2025-07-01 15:23:34,063", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Found 5 relevant sources", "module": "conversation_nodes", "function": "search_knowledge", "line": 259}
{"timestamp": "2025-07-01 15:23:34,064", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:23:34,064", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:23:34,064", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Generating contextual response with 5 search results", "module": "conversation_nodes", "function": "_generate_contextual_response", "line": 559}
{"timestamp": "2025-07-01 15:23:34,119", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:34,125", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.465721 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:34,659", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:34,721", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.816299 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:35,603", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:35,631", "level": "ERROR", "logger": "root", "message": "Groq generation error: no healthy upstream", "module": "llm_client", "function": "generate", "line": 91}
{"timestamp": "2025-07-01 15:23:35,631", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "llm_client", "function": "generate", "line": 249}
{"timestamp": "2025-07-01 15:23:35,632", "level": "ERROR", "logger": "src.conversation.conversation_nodes", "message": "LLM intent detection failed: Groq generation failed: no healthy upstream", "module": "conversation_nodes", "function": "_is_simple_followup_question", "line": 537}
{"timestamp": "2025-07-01 15:23:35,690", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:35,691", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.491033 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:36,252", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:36,255", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.777485 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:37,095", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:37,106", "level": "ERROR", "logger": "root", "message": "Groq generation error: no healthy upstream", "module": "llm_client", "function": "generate", "line": 91}
{"timestamp": "2025-07-01 15:23:37,106", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "llm_client", "function": "generate", "line": 249}
{"timestamp": "2025-07-01 15:23:37,107", "level": "ERROR", "logger": "src.conversation.conversation_nodes", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "conversation_nodes", "function": "_generate_contextual_response", "line": 611}
{"timestamp": "2025-07-01 15:23:37,156", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:37,188", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.464139 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:37,726", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:37,761", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.771815 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:38,593", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:38,598", "level": "ERROR", "logger": "root", "message": "Groq generation error: no healthy upstream", "module": "llm_client", "function": "generate", "line": 91}
{"timestamp": "2025-07-01 15:23:38,599", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "llm_client", "function": "generate", "line": 249}
{"timestamp": "2025-07-01 15:23:38,599", "level": "ERROR", "logger": "src.conversation.conversation_nodes", "message": "LLM intent detection failed: Groq generation failed: no healthy upstream", "module": "conversation_nodes", "function": "_is_simple_followup_question", "line": 537}
{"timestamp": "2025-07-01 15:23:38,687", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:38,690", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.435810 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:39,195", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:39,206", "level": "INFO", "logger": "groq._base_client", "message": "Retrying request to /openai/v1/chat/completions in 0.874982 seconds", "module": "_base_client", "function": "_sleep_for_retry", "line": 1055}
{"timestamp": "2025-07-01 15:23:40,130", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:23:40,135", "level": "ERROR", "logger": "root", "message": "Groq generation error: no healthy upstream", "module": "llm_client", "function": "generate", "line": 91}
{"timestamp": "2025-07-01 15:23:40,135", "level": "ERROR", "logger": "root", "message": "LLM generation failed: Groq generation failed: no healthy upstream", "module": "llm_client", "function": "generate", "line": 249}
{"timestamp": "2025-07-01 15:23:40,136", "level": "ERROR", "logger": "src.conversation.conversation_nodes", "message": "LLM generation failed for context-based response: Groq generation failed: no healthy upstream", "module": "conversation_nodes", "function": "_generate_general_response", "line": 781}
{"timestamp": "2025-07-01 15:23:40,136", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated using sources: ['unknown', 'unknown', 'unknown']", "module": "conversation_nodes", "function": "generate_response", "line": 352}
{"timestamp": "2025-07-01 15:23:40,136", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:23:40,137", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=14", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:23:40,175", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 36822106-bd3a-4710-a661-5463c08cbf40, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:23:40,186", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Processed message for thread 36822106-bd3a-4710-a661-5463c08cbf40", "module": "conversation_manager", "function": "process_user_message", "line": 74}
{"timestamp": "2025-07-01 15:25:04,808", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Created new conversation state for thread 471d6f3c-c512-4f53-b94d-d5f71820a25f", "module": "conversation_graph", "function": "_get_or_create_state", "line": 259}
{"timestamp": "2025-07-01 15:25:04,810", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:25:04,811", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:25:04,811", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: None, turn: 1", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:25:04,812", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:25:04,813", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:25:04,813", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:25:04,814", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated without search results", "module": "conversation_nodes", "function": "generate_response", "line": 354}
{"timestamp": "2025-07-01 15:25:04,814", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:25:04,814", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=None, turns=2", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:25:04,817", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 471d6f3c-c512-4f53-b94d-d5f71820a25f, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:25:04,818", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Started/retrieved conversation for thread: 471d6f3c-c512-4f53-b94d-d5f71820a25f", "module": "conversation_manager", "function": "start_conversation", "line": 53}
{"timestamp": "2025-07-01 15:25:04,819", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Created new conversation state for thread 45aa7b65-67cf-49d3-8572-144560671c82", "module": "conversation_graph", "function": "_get_or_create_state", "line": 259}
{"timestamp": "2025-07-01 15:25:04,822", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:25:04,822", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:25:04,824", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: None, turn: 1", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:25:04,825", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:25:04,826", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:25:04,827", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:25:04,828", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated without search results", "module": "conversation_nodes", "function": "generate_response", "line": 354}
{"timestamp": "2025-07-01 15:25:04,828", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:25:04,829", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=None, turns=2", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:25:04,830", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 45aa7b65-67cf-49d3-8572-144560671c82, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:25:04,832", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Started/retrieved conversation for thread: 45aa7b65-67cf-49d3-8572-144560671c82", "module": "conversation_manager", "function": "start_conversation", "line": 53}
{"timestamp": "2025-07-01 15:25:15,437", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 45aa7b65-67cf-49d3-8572-144560671c82", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 15:25:15,451", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:25:15,453", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:25:15,454", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Conversation has history - treating with partial context", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 424}
{"timestamp": "2025-07-01 15:25:15,454", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Building contextual query from: 'how many incidents are in system'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 15:25:15,454", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Enhanced query to: 'how many incidents are in system (context: )'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 15:25:15,455", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'how many incidents are in system (context: )'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 15:25:15,456", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['many', 'incidents', 'system']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 15:25:15,456", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 15:25:15,457", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 15:25:15,458", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 3", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:25:15,473", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:25:15,473", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 15:25:15,474", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'how many incidents are in system (context: )'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 15:25:15,474", "level": "INFO", "logger": "root", "message": "Query type detected: aggregation", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:25:15,487", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,505", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,523", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,535", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,543", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,545", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 2: Original query: 'how many incidents are in system'", "module": "conversation_nodes", "function": "search_knowledge", "line": 182}
{"timestamp": "2025-07-01 15:25:15,545", "level": "INFO", "logger": "root", "message": "Query type detected: aggregation", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:25:15,552", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,574", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,581", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,594", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,606", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/scroll \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,607", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 15:25:15,608", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'aggregation_results', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 15:25:15,608", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "No sources found in search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 262}
{"timestamp": "2025-07-01 15:25:15,610", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:25:15,611", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:25:15,612", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83d\ude80 Generating follow-up questions", "module": "conversation_nodes", "function": "generate_response", "line": 337}
{"timestamp": "2025-07-01 15:25:15,612", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83d\udd25 FOLLOW-UP QUESTIONS METHOD CALLED \ud83d\udd25", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 791}
{"timestamp": "2025-07-01 15:25:15,613", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Starting follow-up question generation", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 807}
{"timestamp": "2025-07-01 15:25:15,614", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Built context info with length: 328", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 816}
{"timestamp": "2025-07-01 15:25:15,615", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Sending prompt to LLM for follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 842}
{"timestamp": "2025-07-01 15:25:15,990", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:15,991", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "LLM response length: 401", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 844}
{"timestamp": "2025-07-01 15:25:15,991", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Parsed 3 questions from LLM response", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 848}
{"timestamp": "2025-07-01 15:25:15,992", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Generated 3 contextual follow-up questions", "module": "conversation_nodes", "function": "_generate_follow_up_questions", "line": 851}
{"timestamp": "2025-07-01 15:25:15,992", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf Generated 3 suggested questions", "module": "conversation_nodes", "function": "generate_response", "line": 339}
{"timestamp": "2025-07-01 15:25:15,992", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated without search results", "module": "conversation_nodes", "function": "generate_response", "line": 354}
{"timestamp": "2025-07-01 15:25:15,992", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:25:15,992", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=4", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:25:15,995", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 45aa7b65-67cf-49d3-8572-144560671c82, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:25:15,995", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Processed message for thread 45aa7b65-67cf-49d3-8572-144560671c82", "module": "conversation_manager", "function": "process_user_message", "line": 74}
{"timestamp": "2025-07-01 15:25:30,495", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Retrieved existing conversation state for thread 45aa7b65-67cf-49d3-8572-144560671c82", "module": "conversation_graph", "function": "_get_or_create_state", "line": 253}
{"timestamp": "2025-07-01 15:25:30,523", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing greeting node", "module": "conversation_nodes", "function": "greet_user", "line": 34}
{"timestamp": "2025-07-01 15:25:30,544", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing intent understanding node", "module": "conversation_nodes", "function": "understand_intent", "line": 48}
{"timestamp": "2025-07-01 15:25:30,545", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual pattern matched: (that|this|those|these|it|them)", "module": "conversation_nodes", "function": "_is_contextual_query", "line": 414}
{"timestamp": "2025-07-01 15:25:30,545", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Building contextual query from: 'What are these?'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 432}
{"timestamp": "2025-07-01 15:25:30,546", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Enhanced query to: 'What are these? (context: )'", "module": "conversation_nodes", "function": "_build_contextual_query", "line": 496}
{"timestamp": "2025-07-01 15:25:30,547", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Contextual query detected. Enhanced: 'What are these? (context: )'", "module": "conversation_nodes", "function": "understand_intent", "line": 76}
{"timestamp": "2025-07-01 15:25:30,548", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Intent: information_seeking, Keywords: ['these']", "module": "conversation_nodes", "function": "understand_intent", "line": 140}
{"timestamp": "2025-07-01 15:25:30,548", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Current phase after intent: ConversationPhase.SEARCHING", "module": "conversation_nodes", "function": "understand_intent", "line": 141}
{"timestamp": "2025-07-01 15:25:30,548", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Is contextual: True", "module": "conversation_nodes", "function": "understand_intent", "line": 142}
{"timestamp": "2025-07-01 15:25:30,550", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Routing after understanding - intent: information_seeking, turn: 5", "module": "conversation_graph", "function": "_route_after_understanding", "line": 114}
{"timestamp": "2025-07-01 15:25:30,550", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing knowledge search node", "module": "conversation_nodes", "function": "search_knowledge", "line": 147}
{"timestamp": "2025-07-01 15:25:30,552", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Handling contextual query with multiple search strategies", "module": "conversation_nodes", "function": "search_knowledge", "line": 170}
{"timestamp": "2025-07-01 15:25:30,552", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search strategy 1: Enhanced query: 'What are these? (context: )'", "module": "conversation_nodes", "function": "search_knowledge", "line": 173}
{"timestamp": "2025-07-01 15:25:30,553", "level": "INFO", "logger": "root", "message": "Query type detected: semantic_search", "module": "qdrant_query_engine", "function": "process_query", "line": 24}
{"timestamp": "2025-07-01 15:25:30,570", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Request URL: 'https://azurehub1910875317.services.ai.azure.com/models/embeddings?api-version=REDACTED'\nRequest method: 'POST'\nRequest headers:\n    'Content-Type': 'application/json'\n    'Content-Length': '104'\n    'Accept': 'application/json'\n    'x-ms-client-request-id': '9f8e3dde-568f-11f0-8f27-000d3a9b67b4'\n    'api-key': 'REDACTED'\n    'User-Agent': 'azsdk-python-ai-inference/1.0.0b9 Python/3.12.9 (Windows-11-10.0.26100-SP0)'\n    'Authorization': 'REDACTED'\nA body is sent with the request", "module": "_universal", "function": "on_request", "line": 508}
{"timestamp": "2025-07-01 15:25:30,717", "level": "INFO", "logger": "azure.core.pipeline.policies.http_logging_policy", "message": "Response status: 200\nResponse headers:\n    'Cache-Control': 'no-store, no-transform, must-revalidate, no-cache, max-age=0, private'\n    'Transfer-Encoding': 'chunked'\n    'Content-Type': 'application/json'\n    'Content-Encoding': 'REDACTED'\n    'Vary': 'REDACTED'\n    'pragma': 'no-cache'\n    'apim-request-id': 'REDACTED'\n    'request-context': 'REDACTED'\n    'num_chars': 'REDACTED'\n    'num_tokens': 'REDACTED'\n    'prompt_token_len': 'REDACTED'\n    'sampling_token_len': 'REDACTED'\n    'x-content-type-options': 'REDACTED'\n    'x-ms-region': 'REDACTED'\n    'Strict-Transport-Security': 'REDACTED'\n    'Date': 'Tue, 01 Jul 2025 15:25:30 GMT'", "module": "_universal", "function": "on_response", "line": 547}
{"timestamp": "2025-07-01 15:25:30,729", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST http://localhost:6333/collections/rag_documents/points/search \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:31,791", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:31,792", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result type: <class 'dict'>", "module": "conversation_nodes", "function": "search_knowledge", "line": 223}
{"timestamp": "2025-07-01 15:25:31,792", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Search result keys: ['query', 'response', 'confidence_score', 'confidence_level', 'sources', 'total_sources', 'query_type', 'method', 'timestamp']", "module": "conversation_nodes", "function": "search_knowledge", "line": 224}
{"timestamp": "2025-07-01 15:25:31,793", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing 5 sources from search result", "module": "conversation_nodes", "function": "search_knowledge", "line": 235}
{"timestamp": "2025-07-01 15:25:31,793", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Found 5 relevant sources", "module": "conversation_nodes", "function": "search_knowledge", "line": 259}
{"timestamp": "2025-07-01 15:25:31,795", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "\ud83c\udfaf GENERATE_RESPONSE METHOD CALLED \ud83c\udfaf", "module": "conversation_nodes", "function": "generate_response", "line": 287}
{"timestamp": "2025-07-01 15:25:31,796", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Processing response generation node", "module": "conversation_nodes", "function": "generate_response", "line": 288}
{"timestamp": "2025-07-01 15:25:31,796", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Generating contextual response with 5 search results", "module": "conversation_nodes", "function": "_generate_contextual_response", "line": 559}
{"timestamp": "2025-07-01 15:25:31,865", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:33,070", "level": "INFO", "logger": "httpx", "message": "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"", "module": "_client", "function": "_send_single_request", "line": 1025}
{"timestamp": "2025-07-01 15:25:33,071", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated using sources: ['unknown', 'unknown', 'unknown']", "module": "conversation_nodes", "function": "generate_response", "line": 352}
{"timestamp": "2025-07-01 15:25:33,071", "level": "INFO", "logger": "src.conversation.conversation_nodes", "message": "Response generated successfully", "module": "conversation_nodes", "function": "generate_response", "line": 356}
{"timestamp": "2025-07-01 15:25:33,071", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Ending conversation: phase=ConversationPhase.RESPONDING, intent=information_seeking, turns=6", "module": "conversation_graph", "function": "_route_conversation_end", "line": 177}
{"timestamp": "2025-07-01 15:25:33,072", "level": "INFO", "logger": "src.conversation.conversation_graph", "message": "Conversation processed successfully for thread 45aa7b65-67cf-49d3-8572-144560671c82, phase: ConversationPhase.RESPONDING", "module": "conversation_graph", "function": "process_message", "line": 215}
{"timestamp": "2025-07-01 15:25:33,072", "level": "INFO", "logger": "src.conversation.conversation_manager", "message": "Processed message for thread 45aa7b65-67cf-49d3-8572-144560671c82", "module": "conversation_manager", "function": "process_user_message", "line": 74}
{"timestamp": "2025-07-01 15:28:22,919", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Cleaning up 1 idle models", "module": "model_memory_manager", "function": "_cleanup_idle_models", "line": 338}
{"timestamp": "2025-07-01 15:28:23,295", "level": "INFO", "logger": "src.core.model_memory_manager", "message": "Model semantic_chunker_all-MiniLM-L6-v2 unloaded. Current memory: 536.77MB", "module": "model_memory_manager", "function": "_unload_model", "line": 260}
