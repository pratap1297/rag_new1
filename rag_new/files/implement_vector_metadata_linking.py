#!/usr/bin/env python3
"""
Implement Proper Vector-Metadata Linking
This script implements the best practices for linking vectors to metadata
"""
import sys
import os
import uuid
import json
from typing import Dict, List, Any, Optional
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def implement_vector_metadata_linking():
    print("ğŸ”— Implementing Vector-Metadata Linking")
    print("=" * 60)
    
    # 1. Enhanced FAISS Store with Metadata Linking
    enhanced_faiss_code = '''
class EnhancedFAISSStore:
    """FAISS Store with proper metadata linking"""
    
    def __init__(self, index_path: str, dimension: int):
        self.index_path = index_path
        self.dimension = dimension
        self.metadata_path = index_path.replace('.bin', '_metadata.json')
        
        # Vector ID to FAISS index mapping
        self.vector_id_to_index = {}  # {"chunk_001": 0, "chunk_002": 1}
        self.index_to_vector_id = {}  # {0: "chunk_001", 1: "chunk_002"}
        
        self._initialize_index()
        self._load_metadata_mapping()
    
    def add_vectors_with_metadata(self, vectors: List[List[float]], 
                                 metadata_list: List[Dict[str, Any]]) -> List[str]:
        """Add vectors with proper metadata linking"""
        vector_ids = []
        
        for i, (vector, metadata) in enumerate(zip(vectors, metadata_list)):
            # Generate unique vector ID
            vector_id = f"chunk_{uuid.uuid4().hex[:8]}_{metadata.get('doc_id', 'unknown')}"
            
            # Add to FAISS index
            current_index = self.index.ntotal
            self.index.add(np.array([vector], dtype=np.float32))
            
            # Create bidirectional mapping
            self.vector_id_to_index[vector_id] = current_index
            self.index_to_vector_id[current_index] = vector_id
            
            # Store enhanced metadata
            enhanced_metadata = {
                **metadata,
                "vector_id": vector_id,
                "faiss_index": current_index,
                "created_at": datetime.now().isoformat()
            }
            
            vector_ids.append(vector_id)
        
        # Save mappings
        self._save_metadata_mapping()
        self._save_index()
        
        return vector_ids
    
    def search_with_metadata(self, query_vector: List[float], 
                           k: int = 5) -> List[Dict[str, Any]]:
        """Search and return results with proper metadata"""
        # FAISS search
        similarities, indices = self.index.search(
            np.array([query_vector], dtype=np.float32), k
        )
        
        results = []
        for similarity, faiss_idx in zip(similarities[0], indices[0]):
            if faiss_idx == -1:  # No more results
                break
                
            # Get vector ID from FAISS index
            vector_id = self.index_to_vector_id.get(faiss_idx)
            
            if vector_id:
                result = {
                    "vector_id": vector_id,
                    "faiss_index": int(faiss_idx),
                    "similarity_score": float(similarity),
                    "doc_id": vector_id.split('_')[-1] if '_' in vector_id else "unknown"
                }
                results.append(result)
        
        return results
    
    def _save_metadata_mapping(self):
        """Save vector ID mappings"""
        mapping_data = {
            "vector_id_to_index": self.vector_id_to_index,
            "index_to_vector_id": {str(k): v for k, v in self.index_to_vector_id.items()},
            "total_vectors": self.index.ntotal,
            "last_updated": datetime.now().isoformat()
        }
        
        with open(self.metadata_path, 'w') as f:
            json.dump(mapping_data, f, indent=2)
    
    def _load_metadata_mapping(self):
        """Load vector ID mappings"""
        if os.path.exists(self.metadata_path):
            try:
                with open(self.metadata_path, 'r') as f:
                    mapping_data = json.load(f)
                
                self.vector_id_to_index = mapping_data.get("vector_id_to_index", {})
                self.index_to_vector_id = {
                    int(k): v for k, v in mapping_data.get("index_to_vector_id", {}).items()
                }
            except Exception as e:
                print(f"Warning: Could not load metadata mapping: {e}")
                self.vector_id_to_index = {}
                self.index_to_vector_id = {}
'''
    
    # 2. Enhanced Metadata Store with Vector Linking
    enhanced_metadata_code = '''
class EnhancedMetadataStore:
    """Metadata store with proper vector linking"""
    
    def __init__(self, base_path: str = "data/metadata"):
        self.base_path = base_path
        self.collections = {}
        
        # Key collections for vector linking
        self.vector_metadata = {}  # vector_id -> full metadata
        self.doc_vectors = {}      # doc_id -> [vector_ids]
        self.chunk_vectors = {}    # chunk_id -> vector_id
    
    def add_chunk_with_vector(self, chunk_data: Dict[str, Any], 
                            vector_id: str) -> str:
        """Add chunk metadata with vector linking"""
        chunk_id = chunk_data.get('chunk_id') or f"chunk_{uuid.uuid4().hex[:8]}"
        
        # Enhanced chunk metadata
        enhanced_metadata = {
            **chunk_data,
            "chunk_id": chunk_id,
            "vector_id": vector_id,
            "created_at": datetime.now().isoformat(),
            "type": "chunk"
        }
        
        # Store in multiple indexes for fast lookup
        self.vector_metadata[vector_id] = enhanced_metadata
        self.chunk_vectors[chunk_id] = vector_id
        
        # Group by document
        doc_id = chunk_data.get('doc_id', 'unknown')
        if doc_id not in self.doc_vectors:
            self.doc_vectors[doc_id] = []
        self.doc_vectors[doc_id].append(vector_id)
        
        return chunk_id
    
    def get_metadata_by_vector_id(self, vector_id: str) -> Optional[Dict[str, Any]]:
        """Get metadata using vector ID"""
        return self.vector_metadata.get(vector_id)
    
    def get_vectors_by_doc_id(self, doc_id: str) -> List[str]:
        """Get all vector IDs for a document"""
        return self.doc_vectors.get(doc_id, [])
    
    def get_all_files_with_vectors(self) -> List[Dict[str, Any]]:
        """Get all files with their vector information"""
        files = []
        for doc_id, vector_ids in self.doc_vectors.items():
            if vector_ids:
                # Get metadata from first chunk
                first_vector_metadata = self.vector_metadata.get(vector_ids[0], {})
                
                file_info = {
                    "doc_id": doc_id,
                    "filename": first_vector_metadata.get('filename', 'unknown'),
                    "chunk_count": len(vector_ids),
                    "vector_count": len(vector_ids),
                    "file_path": first_vector_metadata.get('file_path', ''),
                    "created_at": first_vector_metadata.get('created_at', ''),
                    "vector_ids": vector_ids
                }
                files.append(file_info)
        
        return files
    
    def get_all_chunks_with_vectors(self) -> List[Dict[str, Any]]:
        """Get all chunks with their vector information"""
        return list(self.vector_metadata.values())
'''
    
    # 3. Enhanced Query Engine with Proper Linking
    enhanced_query_code = '''
class EnhancedQueryEngine:
    """Query engine with proper vector-metadata linking"""
    
    def __init__(self, faiss_store, embedder, llm_client, metadata_store, config_manager):
        self.faiss_store = faiss_store
        self.embedder = embedder
        self.llm_client = llm_client
        self.metadata_store = metadata_store
        self.config = config_manager.get_config()
    
    def process_query(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """Process query with proper metadata linking"""
        try:
            # Generate query embedding
            query_embedding = self.embedder.embed_text(query)
            
            # Search FAISS with metadata
            search_results = self.faiss_store.search_with_metadata(
                query_vector=query_embedding, 
                k=max_results
            )
            
            # Enrich results with full metadata
            enriched_results = []
            for result in search_results:
                vector_id = result.get('vector_id')
                if vector_id:
                    # Get full metadata using vector ID
                    metadata = self.metadata_store.get_metadata_by_vector_id(vector_id)
                    if metadata:
                        enriched_result = {
                            **result,
                            "content": metadata.get('content', ''),
                            "doc_id": metadata.get('doc_id', 'unknown'),
                            "filename": metadata.get('filename', 'unknown'),
                            "chunk_id": metadata.get('chunk_id', 'unknown'),
                            "page_number": metadata.get('page_number'),
                            "chunk_index": metadata.get('chunk_index')
                        }
                        enriched_results.append(enriched_result)
            
            # Generate LLM response
            response = self._generate_response(query, enriched_results)
            
            return {
                "query": query,
                "response": response,
                "results": enriched_results,
                "total_results": len(enriched_results),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "query": query,
                "response": f"Error processing query: {e}",
                "results": [],
                "total_results": 0,
                "error": str(e)
            }
    
    def _generate_response(self, query: str, results: List[Dict[str, Any]]) -> str:
        """Generate response with proper source attribution"""
        if not results:
            return "I couldn't find any relevant information to answer your question."
        
        # Build context with proper source attribution
        context_parts = []
        for i, result in enumerate(results[:3], 1):
            content = result.get('content', '')[:300]
            filename = result.get('filename', 'unknown')
            doc_id = result.get('doc_id', 'unknown')
            
            context_parts.append(
                f"Source {i} (Document: {filename}, ID: {doc_id}): {content}"
            )
        
        context = "\\n\\n".join(context_parts)
        
        prompt = f"""Based on the following sources, answer the user's question. 
        Always cite which document(s) you're referencing in your answer.

Sources:
{context}

Question: {query}

Answer:"""
        
        try:
            return self.llm_client.generate(prompt)
        except Exception as e:
            return f"I found relevant information but couldn't generate a response: {e}"
'''
    
    print("ğŸ“‹ Vector-Metadata Linking Implementation Plan:")
    print("\n1. ğŸ”— **Vector ID-Based Linking** (Recommended)")
    print("   â€¢ Each vector gets unique ID: chunk_abc123_doc456")
    print("   â€¢ Bidirectional mapping: vector_id â†” faiss_index")
    print("   â€¢ Metadata indexed by vector_id")
    
    print("\n2. ğŸ“Š **Enhanced Data Structures**")
    print("   â€¢ vector_metadata: {vector_id: full_metadata}")
    print("   â€¢ doc_vectors: {doc_id: [vector_ids]}")
    print("   â€¢ chunk_vectors: {chunk_id: vector_id}")
    
    print("\n3. ğŸ” **Improved Search Flow**")
    print("   â€¢ Query â†’ FAISS search â†’ vector_ids â†’ metadata lookup")
    print("   â€¢ Proper source attribution with document names")
    print("   â€¢ No more 'doc_unknown' issues")
    
    print("\n4. ğŸ’¾ **Persistent Mapping Storage**")
    print("   â€¢ Save vector_id mappings to JSON file")
    print("   â€¢ Survive system restarts")
    print("   â€¢ Automatic recovery and validation")
    
    # Create implementation files
    print("\nğŸ› ï¸ Creating implementation files...")
    
    # Save enhanced implementations
    with open("enhanced_faiss_store.py", "w") as f:
        f.write("# Enhanced FAISS Store with Metadata Linking\n")
        f.write("import numpy as np\nimport json\nimport uuid\nfrom datetime import datetime\nimport os\n\n")
        f.write(enhanced_faiss_code)
    
    with open("enhanced_metadata_store.py", "w") as f:
        f.write("# Enhanced Metadata Store with Vector Linking\n")
        f.write("import uuid\nfrom datetime import datetime\nfrom typing import Dict, List, Any, Optional\n\n")
        f.write(enhanced_metadata_code)
    
    with open("enhanced_query_engine.py", "w") as f:
        f.write("# Enhanced Query Engine with Proper Linking\n")
        f.write("from datetime import datetime\nfrom typing import Dict, List, Any\n\n")
        f.write(enhanced_query_code)
    
    print("   âœ… enhanced_faiss_store.py")
    print("   âœ… enhanced_metadata_store.py") 
    print("   âœ… enhanced_query_engine.py")
    
    print("\nğŸ¯ **Benefits of This Approach:**")
    print("   â€¢ âœ… Reliable vector-metadata linking")
    print("   â€¢ âœ… Proper document identification")
    print("   â€¢ âœ… Fast lookups (O(1) for metadata)")
    print("   â€¢ âœ… Survives system restarts")
    print("   â€¢ âœ… Easy debugging and maintenance")
    print("   â€¢ âœ… Scalable to millions of vectors")
    
    print("\nğŸš€ **Next Steps:**")
    print("   1. Integrate enhanced classes into your system")
    print("   2. Clear existing corrupted data")
    print("   3. Re-ingest documents with proper linking")
    print("   4. Test queries - should show proper document names")
    
    print("\nâœ… Vector-Metadata Linking Implementation Complete!")

if __name__ == "__main__":
    implement_vector_metadata_linking() 